{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import itertools\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import copy\n",
    "import scipy.stats\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary data\n",
    "ppi = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI.csv', encoding = 'utf-8', compression = 'gzip', low_memory = False, sep = '\\t')\n",
    "uniprot_ids = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\Metadata.csv', encoding = 'utf-8', compression = 'gzip', low_memory = False, sep = '\\t')\n",
    "ppi2 = ppi.copy()\n",
    "uniprot_ids = uniprot_ids.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIAMOnD algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A DIseAse MOdule Detection (DIAMOnD) Algorithm Derived from a Systematic Analysis of Connectivity Patterns of Disease Proteins in the Human Interactome:**\n",
    "\n",
    "Disease associated proteins do not reside within locally dense communities and instead identify connectivity significance as the most predictive quantity.\n",
    "Disease Module Detection (DIAMOnD) algorithm to identify the full disease module around a set of known disease proteins.\n",
    "\n",
    "Building on the observation that the connectivity significance is highly distinctive for known disease proteins, we propose the following algorithm to infer yet unknown disease proteins, and hence to identify the respective disease module:\n",
    "\n",
    "* The connectivity significance is determined for all proteins connected to any of the s0 seed proteins.\n",
    "* The proteins are ranked according to their respective p-values.\n",
    "* The protein with the highest rank (i.e. lowest p-value) is added to the set of seed nodes, increasing their number from s0 â†’s1 = s0+1.\n",
    "* Steps (i)-(iii) are repeated with the expanded set of seed proteins, pulling in one protein at a time into the growing disease module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "        usage: python3 DIAMOnD.py network_file seed_file n alpha(optional) outfile_name (optional)\n",
      "        -----------------------------------------------------------------\n",
      "        network_file : The edgelist must be provided as any delimiter-separated\n",
      "                       table. Make sure the delimiter does not exit in gene IDs\n",
      "                       and is consistent across the file.\n",
      "                       The first two columns of the table will be\n",
      "                       interpreted as an interaction gene1 <==> gene2\n",
      "        seed_file    : table containing the seed genes (if table contains\n",
      "                       more than one column they must be tab-separated;\n",
      "                       the first column will be used only)\n",
      "        n            : desired number of DIAMOnD genes, 200 is a reasonable\n",
      "                       starting point.\n",
      "        alpha        : an integer representing weight of the seeds,default\n",
      "                       value is set to 1\n",
      "        outfile_name : results will be saved under this file name\n",
      "                       by default the outfile_name is set to \"first_n_added_nodes_weight_alpha.txt\"\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# https://github.com/dinaghiassian/DIAMOnD\n",
    "\n",
    "# =============================================================================\n",
    "print(' ')\n",
    "print('        usage: python3 DIAMOnD.py network_file seed_file n alpha(optional) outfile_name (optional)')\n",
    "print('        -----------------------------------------------------------------')\n",
    "print('        network_file : The edgelist must be provided as any delimiter-separated')\n",
    "print('                       table. Make sure the delimiter does not exit in gene IDs')\n",
    "print('                       and is consistent across the file.')\n",
    "print('                       The first two columns of the table will be')\n",
    "print('                       interpreted as an interaction gene1 <==> gene2')\n",
    "print('        seed_file    : table containing the seed genes (if table contains')\n",
    "print('                       more than one column they must be tab-separated;')\n",
    "print('                       the first column will be used only)')\n",
    "print('        n            : desired number of DIAMOnD genes, 200 is a reasonable')\n",
    "print('                       starting point.')\n",
    "print('        alpha        : an integer representing weight of the seeds,default')\n",
    "print('                       value is set to 1')\n",
    "print('        outfile_name : results will be saved under this file name')\n",
    "print('                       by default the outfile_name is set to \"first_n_added_nodes_weight_alpha.txt\"')\n",
    "print(' ')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def read_input(network_file, seed_file):\n",
    "    \"\"\"\n",
    "    Reads the network and the list of seed genes from external files.\n",
    "    * The edgelist must be provided as a tab-separated table. The\n",
    "    first two columns of the table will be interpreted as an\n",
    "    interaction gene1 <==> gene2\n",
    "    * The seed genes mus be provided as a table. If the table has more\n",
    "    than one column, they must be tab-separated. The first column will\n",
    "    be used only.\n",
    "    * Lines that start with '#' will be ignored in both cases\n",
    "    \"\"\"\n",
    "\n",
    "    sniffer = csv.Sniffer()\n",
    "    line_delimiter = None\n",
    "    for line in open(network_file, 'r'):\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        else:\n",
    "            dialect = sniffer.sniff(line)\n",
    "            line_delimiter = dialect.delimiter\n",
    "            break\n",
    "    if line_delimiter == None:\n",
    "        print\n",
    "        'network_file format not correct'\n",
    "        sys.exit(0)\n",
    "\n",
    "    # read the network:\n",
    "    G = nx.Graph()\n",
    "    for line in open(network_file, 'r'):\n",
    "        # lines starting with '#' will be ignored\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        # The first two columns in the line will be interpreted as an\n",
    "        # interaction gene1 <=> gene2\n",
    "        # line_data   = line.strip().split('\\t')\n",
    "        line_data = line.strip().split(line_delimiter)\n",
    "        node1 = line_data[0]\n",
    "        node2 = line_data[1]\n",
    "        G.add_edge(node1, node2)\n",
    "\n",
    "    # read the seed genes:\n",
    "    seed_genes = set()\n",
    "    for line in open(seed_file, 'r'):\n",
    "        # lines starting with '#' will be ignored\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        # the first column in the line will be interpreted as a seed\n",
    "        # gene:\n",
    "        line_data = line.strip().split('\\t')\n",
    "        seed_gene = line_data[0]\n",
    "        seed_genes.add(seed_gene)\n",
    "\n",
    "    return G, seed_genes\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "def compute_all_gamma_ln(N):\n",
    "    \"\"\"\n",
    "    precomputes all logarithmic gammas\n",
    "    \"\"\"\n",
    "    gamma_ln = {}\n",
    "    for i in range(1, N + 1):\n",
    "        gamma_ln[i] = scipy.special.gammaln(i)\n",
    "\n",
    "    return gamma_ln\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def logchoose(n, k, gamma_ln):\n",
    "    if n - k + 1 <= 0:\n",
    "        return scipy.infty\n",
    "    lgn1 = gamma_ln[n + 1]\n",
    "    lgk1 = gamma_ln[k + 1]\n",
    "    lgnk1 = gamma_ln[n - k + 1]\n",
    "    return lgn1 - [lgnk1 + lgk1]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def gauss_hypergeom(x, r, b, n, gamma_ln):\n",
    "    return np.exp(logchoose(r, x, gamma_ln) +\n",
    "                  logchoose(b, n - x, gamma_ln) -\n",
    "                  logchoose(r + b, n, gamma_ln))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def pvalue(kb, k, N, s, gamma_ln):\n",
    "    \"\"\"\n",
    "    -------------------------------------------------------------------\n",
    "    Computes the p-value for a node that has kb out of k links to\n",
    "    seeds, given that there's a total of s sees in a network of N nodes.\n",
    "    p-val = \\sum_{n=kb}^{k} HypergemetricPDF(n,k,N,s)\n",
    "    -------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    p = 0.0\n",
    "    for n in range(kb, k + 1):\n",
    "        if n > s:\n",
    "            break\n",
    "        prob = gauss_hypergeom(n, s, N - s, k, gamma_ln)\n",
    "        # print prob\n",
    "        p += prob\n",
    "\n",
    "    if p > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "    # =============================================================================\n",
    "\n",
    "\n",
    "def get_neighbors_and_degrees(G):\n",
    "    neighbors, all_degrees = {}, {}\n",
    "    for node in G.nodes():\n",
    "        nn = set(G.neighbors(node))\n",
    "        neighbors[node] = nn\n",
    "        all_degrees[node] = G.degree(node)\n",
    "\n",
    "    return neighbors, all_degrees\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Reduce number of calculations\n",
    "# =============================================================================\n",
    "def reduce_not_in_cluster_nodes(all_degrees, neighbors, G, not_in_cluster, cluster_nodes, alpha):\n",
    "    reduced_not_in_cluster = {}\n",
    "    kb2k = defaultdict(dict)\n",
    "    for node in not_in_cluster:\n",
    "\n",
    "        k = all_degrees[node]\n",
    "        kb = 0\n",
    "        # Going through all neighbors and counting the number of module neighbors\n",
    "        for neighbor in neighbors[node]:\n",
    "            if neighbor in cluster_nodes:\n",
    "                kb += 1\n",
    "\n",
    "        # adding wights to the the edges connected to seeds\n",
    "        k += (alpha - 1) * kb\n",
    "        kb += (alpha - 1) * kb\n",
    "        kb2k[kb][k] = node\n",
    "\n",
    "    # Going to choose the node with largest kb, given k\n",
    "    k2kb = defaultdict(dict)\n",
    "    for kb, k2node in kb2k.items():\n",
    "        min_k = min(k2node.keys())\n",
    "        node = k2node[min_k]\n",
    "        k2kb[min_k][kb] = node\n",
    "\n",
    "    for k, kb2node in k2kb.items():\n",
    "        max_kb = max(kb2node.keys())\n",
    "        node = kb2node[max_kb]\n",
    "        reduced_not_in_cluster[node] = (max_kb, k)\n",
    "\n",
    "    return reduced_not_in_cluster\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "#   C O R E    A L G O R I T H M\n",
    "# ======================================================================================\n",
    "def diamond_iteration_of_first_X_nodes(G, S, X, alpha):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - G:     graph\n",
    "    - S:     seeds\n",
    "    - X:     the number of iterations, i.e only the first X gened will be\n",
    "             pulled in\n",
    "    - alpha: seeds weight\n",
    "    Returns:\n",
    "    --------\n",
    "    - added_nodes: ordered list of nodes in the order by which they\n",
    "      are agglomerated. Each entry has 4 info:\n",
    "      * name : dito\n",
    "      * k    : degree of the node\n",
    "      * kb   : number of +1 neighbors\n",
    "      * p    : p-value at agglomeration\n",
    "    \"\"\"\n",
    "\n",
    "    N = G.number_of_nodes()\n",
    "\n",
    "    added_nodes = []\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Setting up dictionaries with all neighbor lists\n",
    "    # and all degrees\n",
    "    # ------------------------------------------------------------------\n",
    "    neighbors, all_degrees = get_neighbors_and_degrees(G)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Setting up initial set of nodes in cluster\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    cluster_nodes = set(S)\n",
    "    not_in_cluster = set()\n",
    "    s0 = len(cluster_nodes)\n",
    "\n",
    "    s0 += (alpha - 1) * s0\n",
    "    N += (alpha - 1) * s0\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # precompute the logarithmic gamma functions\n",
    "    # ------------------------------------------------------------------\n",
    "    gamma_ln = compute_all_gamma_ln(N + 1)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Setting initial set of nodes not in cluster\n",
    "    # ------------------------------------------------------------------\n",
    "    for node in cluster_nodes:\n",
    "        not_in_cluster |= neighbors[node]\n",
    "    not_in_cluster -= cluster_nodes\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #\n",
    "    # M A I N     L O O P\n",
    "    #\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    all_p = {}\n",
    "\n",
    "    while len(added_nodes) < X:\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        #\n",
    "        # Going through all nodes that are not in the cluster yet and\n",
    "        # record k, kb and p\n",
    "        #\n",
    "        # ------------------------------------------------------------------\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        pmin = 10\n",
    "        next_node = 'nix'\n",
    "        reduced_not_in_cluster = reduce_not_in_cluster_nodes(all_degrees,\n",
    "                                                             neighbors, G,\n",
    "                                                             not_in_cluster,\n",
    "                                                             cluster_nodes, alpha)\n",
    "\n",
    "        for node, kbk in reduced_not_in_cluster.items():\n",
    "            # Getting the p-value of this kb,k\n",
    "            # combination and save it in all_p, so computing it only once!\n",
    "            kb, k = kbk\n",
    "            try:\n",
    "                p = all_p[(k, kb, s0)]\n",
    "            except KeyError:\n",
    "                p = pvalue(kb, k, N, s0, gamma_ln)\n",
    "                all_p[(k, kb, s0)] = p\n",
    "\n",
    "            # recording the node with smallest p-value\n",
    "            if p < pmin:\n",
    "                pmin = p\n",
    "                next_node = node\n",
    "\n",
    "            info[node] = (k, kb, p)\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Adding node with smallest p-value to the list of aaglomerated nodes\n",
    "        # ---------------------------------------------------------------------\n",
    "        added_nodes.append((next_node,\n",
    "                            info[next_node][0],\n",
    "                            info[next_node][1],\n",
    "                            info[next_node][2]))\n",
    "\n",
    "        # Updating the list of cluster nodes and s0\n",
    "        cluster_nodes.add(next_node)\n",
    "        s0 = len(cluster_nodes)\n",
    "        not_in_cluster |= (neighbors[next_node] - cluster_nodes)\n",
    "        not_in_cluster.remove(next_node)\n",
    "\n",
    "    return added_nodes\n",
    "\n",
    "\n",
    "# ===========================================================================\n",
    "#\n",
    "#   M A I N    D I A M O n D    A L G O R I T H M\n",
    "#\n",
    "# ===========================================================================\n",
    "def DIAMOnD(G_original, seed_genes, max_number_of_added_nodes, alpha, outfile=None):\n",
    "    \"\"\"\n",
    "    Runs the DIAMOnD algorithm\n",
    "    Input:\n",
    "    ------\n",
    "     - G_original :\n",
    "             The network\n",
    "     - seed_genes :\n",
    "             a set of seed genes\n",
    "     - max_number_of_added_nodes:\n",
    "             after how many added nodes should the algorithm stop\n",
    "     - alpha:\n",
    "             given weight to the sees\n",
    "     - outfile:\n",
    "             filename for the output generates by the algorithm,\n",
    "             if not given the program will name it 'first_x_added_nodes.txt'\n",
    "     Returns:\n",
    "     --------\n",
    "      - added_nodes: A list with 4 entries at each element:\n",
    "            * name : name of the node\n",
    "            * k    : degree of the node\n",
    "            * kb   : number of neighbors that are part of the module (at agglomeration)\n",
    "            * p    : connectivity p-value at agglomeration\n",
    "      -\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. throwing away the seed genes that are not in the network\n",
    "    all_genes_in_network = set(G_original.nodes())\n",
    "    seed_genes = set(seed_genes)\n",
    "    disease_genes = seed_genes & all_genes_in_network\n",
    "\n",
    "    if len(disease_genes) != len(seed_genes):\n",
    "        print(\"DIAMOnD(): ignoring %s of %s seed genes that are not in the network\" % (\n",
    "            len(seed_genes - all_genes_in_network), len(seed_genes)))\n",
    "\n",
    "    # 2. agglomeration algorithm.\n",
    "    added_nodes = diamond_iteration_of_first_X_nodes(G_original,\n",
    "                                                     disease_genes,\n",
    "                                                     max_number_of_added_nodes, alpha)\n",
    "    # 3. saving the results\n",
    "    with open(outfile, 'w') as fout:\n",
    "        fout.write('\\t'.join(['#rank', 'DIAMOnD_node', 'p_hyper']) + '\\n')\n",
    "        rank = 0\n",
    "        for DIAMOnD_node_info in added_nodes:\n",
    "            rank += 1\n",
    "            DIAMOnD_node = DIAMOnD_node_info[0]\n",
    "            p = float(DIAMOnD_node_info[3])\n",
    "\n",
    "            fout.write('\\t'.join(map(str, ([rank, DIAMOnD_node, p]))) + '\\n')\n",
    "    return added_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the most porminent diseases in the protein-protein interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diseases</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schizophrenia</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malignant neoplasm of breast</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breast Carcinoma</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malignant neoplasm of prostate</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intellectual Disability</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Liver carcinoma</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorectal Carcinoma</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mammary Neoplasms</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hypertensive disease</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Obesity</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Diseases  Count\n",
       "0                   Schizophrenia    365\n",
       "1    Malignant neoplasm of breast    359\n",
       "2                Breast Carcinoma    307\n",
       "3  Malignant neoplasm of prostate    225\n",
       "4         Intellectual Disability    210\n",
       "5                 Liver carcinoma    203\n",
       "6            Colorectal Carcinoma    180\n",
       "7               Mammary Neoplasms    153\n",
       "8            Hypertensive disease    137\n",
       "9                         Obesity    135"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the uniprot IDs in the ass network and check which ones are present in the uniprot\n",
    "ppi_uniprot_ids = list(set(list(ppi2.UniprotAccession_A) + list(ppi2.UniprotAccession_B)))\n",
    "uniprot_ppi = uniprot_ids[uniprot_ids['UniprotAccession'].isin(ppi_uniprot_ids)]\n",
    "uniprot_ppi = uniprot_ppi.astype(str)\n",
    "\n",
    "# Create a new dataframe containing the disease terms and the amount they are present in the original dataframe\n",
    "disease_counts_ppi = pd.DataFrame(uniprot_ppi['DisGeNet_disease_name'].str.split('; ', expand=True).stack().value_counts()).reset_index()\n",
    "disease_counts_ppi.columns = ['Diseases', 'Count']\n",
    "disease_counts_ppi = disease_counts_ppi.drop([0]).reset_index(drop = True)\n",
    "\n",
    "#display the top 30 disease terms and the amount of times they are present7\n",
    "disease_counts_ppi.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check how many disease-related proteins are in the network and create a randomized sample op nodes to optimize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all proteins that are associated with Breast Carcinoma in the network and \n",
    "# filter only the nodes that have annotations\n",
    "disease_ppi = uniprot_ppi[uniprot_ppi['DisGeNet_disease_name'].str.contains('Breast Carcinoma')].reset_index(drop = True)\n",
    "\n",
    "x = ['GO_biological_process', \n",
    "     'GO_cellular_component', \n",
    "     'GO_molecular_function', \n",
    "     'Reactome_ID', \n",
    "     'HPA_Subcellular_location']\n",
    "for ele in x:\n",
    "    disease_ppi = disease_ppi[disease_ppi[ele] != 'nan']\n",
    "\n",
    "seeds = disease_ppi.UniprotAccession.tolist()\n",
    "\n",
    "# Create all empty dataframes\n",
    "x = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
    "\n",
    "# No filtration\n",
    "df_5 = pd.DataFrame()\n",
    "df_5['Amount of added proteins'], \\\n",
    "df_5['alpha = 1'], \\\n",
    "df_5['alpha = 2'], \\\n",
    "df_5['alpha = 3'], \\\n",
    "df_5['alpha = 4'], \\\n",
    "df_5['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                    [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_5 = df_5.set_index('Amount of added proteins')\n",
    "\n",
    "df_10 = pd.DataFrame()\n",
    "df_10['Amount of added proteins'], \\\n",
    "df_10['alpha = 1'], \\\n",
    "df_10['alpha = 2'], \\\n",
    "df_10['alpha = 3'], \\\n",
    "df_10['alpha = 4'], \\\n",
    "df_10['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                     [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_10 = df_10.set_index('Amount of added proteins')\n",
    "\n",
    "df_15 = pd.DataFrame()\n",
    "df_15['Amount of added proteins'], \\\n",
    "df_15['alpha = 1'], \\\n",
    "df_15['alpha = 2'], \\\n",
    "df_15['alpha = 3'], \\\n",
    "df_15['alpha = 4'], \\\n",
    "df_15['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                     [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_15 = df_15.set_index('Amount of added proteins')\n",
    "\n",
    "# Reactome general filtration\n",
    "df_p5 = pd.DataFrame()\n",
    "df_p5['Amount of added proteins'], \\\n",
    "df_p5['alpha = 1'], \\\n",
    "df_p5['alpha = 2'], \\\n",
    "df_p5['alpha = 3'], \\\n",
    "df_p5['alpha = 4'], \\\n",
    "df_p5['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                     [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_p5 = df_p5.set_index('Amount of added proteins')\n",
    "\n",
    "df_p10 = pd.DataFrame()\n",
    "df_p10['Amount of added proteins'], \\\n",
    "df_p10['alpha = 1'], \\\n",
    "df_p10['alpha = 2'], \\\n",
    "df_p10['alpha = 3'], \\\n",
    "df_p10['alpha = 4'], \\\n",
    "df_p10['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                      [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_p10 = df_p10.set_index('Amount of added proteins')\n",
    "\n",
    "df_p15 = pd.DataFrame()\n",
    "df_p15['Amount of added proteins'], \\\n",
    "df_p15['alpha = 1'], \\\n",
    "df_p15['alpha = 2'], \\\n",
    "df_p15['alpha = 3'], \\\n",
    "df_p15['alpha = 4'], \\\n",
    "df_p15['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                      [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_p15 = df_p15.set_index('Amount of added proteins')\n",
    "\n",
    "# Reactome leaf pathway filtration\n",
    "df_lp5 = pd.DataFrame()\n",
    "df_lp5['Amount of added proteins'], \\\n",
    "df_lp5['alpha = 1'], \\\n",
    "df_lp5['alpha = 2'], \\\n",
    "df_lp5['alpha = 3'], \\\n",
    "df_lp5['alpha = 4'], \\\n",
    "df_lp5['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                      [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_lp5 = df_lp5.set_index('Amount of added proteins')\n",
    "\n",
    "df_lp10 = pd.DataFrame()\n",
    "df_lp10['Amount of added proteins'], \\\n",
    "df_lp10['alpha = 1'], \\\n",
    "df_lp10['alpha = 2'], \\\n",
    "df_lp10['alpha = 3'], \\\n",
    "df_lp10['alpha = 4'], \\\n",
    "df_lp10['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                       [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_lp10 = df_lp10.set_index('Amount of added proteins')\n",
    "\n",
    "df_lp15 = pd.DataFrame()\n",
    "df_lp15['Amount of added proteins'], \\\n",
    "df_lp15['alpha = 1'], \\\n",
    "df_lp15['alpha = 2'], \\\n",
    "df_lp15['alpha = 3'], \\\n",
    "df_lp15['alpha = 4'], \\\n",
    "df_lp15['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                       [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_lp15 = df_lp15.set_index('Amount of added proteins')\n",
    "\n",
    "# Subcellular location filtration\n",
    "df_l5 = pd.DataFrame()\n",
    "df_l5['Amount of added proteins'], \\\n",
    "df_l5['alpha = 1'], \\\n",
    "df_l5['alpha = 2'], \\\n",
    "df_l5['alpha = 3'], \\\n",
    "df_l5['alpha = 4'], \\\n",
    "df_l5['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                     [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_l5 = df_l5.set_index('Amount of added proteins')\n",
    "\n",
    "df_l10 = pd.DataFrame()\n",
    "df_l10['Amount of added proteins'], \\\n",
    "df_l10['alpha = 1'], \\\n",
    "df_l10['alpha = 2'], \\\n",
    "df_l10['alpha = 3'], \\\n",
    "df_l10['alpha = 4'], \\\n",
    "df_l10['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                      [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_l10 = df_l10.set_index('Amount of added proteins')\n",
    "\n",
    "df_l15 = pd.DataFrame()\n",
    "df_l15['Amount of added proteins'], \\\n",
    "df_l15['alpha = 1'], \\\n",
    "df_l15['alpha = 2'], \\\n",
    "df_l15['alpha = 3'], \\\n",
    "df_l15['alpha = 4'], \\\n",
    "df_l15['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                      [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_l15 = df_l15.set_index('Amount of added proteins')\n",
    "\n",
    "# GO filtration\n",
    "df_go5 = pd.DataFrame()\n",
    "df_go5['Amount of added proteins'], \\\n",
    "df_go5['alpha = 1'], \\\n",
    "df_go5['alpha = 2'], \\\n",
    "df_go5['alpha = 3'], \\\n",
    "df_go5['alpha = 4'], \\\n",
    "df_go5['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                      [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_go5 = df_go5.set_index('Amount of added proteins')\n",
    "\n",
    "df_go10 = pd.DataFrame()\n",
    "df_go10['Amount of added proteins'], \\\n",
    "df_go10['alpha = 1'], \\\n",
    "df_go10['alpha = 2'], \\\n",
    "df_go10['alpha = 3'], \\\n",
    "df_go10['alpha = 4'], \\\n",
    "df_go10['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                       [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_go10 = df_go10.set_index('Amount of added proteins')\n",
    "\n",
    "df_go15 = pd.DataFrame()\n",
    "df_go15['Amount of added proteins'], \\\n",
    "df_go15['alpha = 1'], \\\n",
    "df_go15['alpha = 2'], \\\n",
    "df_go15['alpha = 3'], \\\n",
    "df_go15['alpha = 4'], \\\n",
    "df_go15['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                       [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_go15 = df_go15.set_index('Amount of added proteins')\n",
    "\n",
    "# General reactome filtration + subcellular location filtration\n",
    "df_pl5 = pd.DataFrame()\n",
    "df_pl5['Amount of added proteins'], \\\n",
    "df_pl5['alpha = 1'], \\\n",
    "df_pl5['alpha = 2'], \\\n",
    "df_pl5['alpha = 3'], \\\n",
    "df_pl5['alpha = 4'], \\\n",
    "df_pl5['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                      [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_pl5 = df_pl5.set_index('Amount of added proteins')\n",
    "\n",
    "df_pl10 = pd.DataFrame()\n",
    "df_pl10['Amount of added proteins'], \\\n",
    "df_pl10['alpha = 1'], \\\n",
    "df_pl10['alpha = 2'], \\\n",
    "df_pl10['alpha = 3'], \\\n",
    "df_pl10['alpha = 4'], \\\n",
    "df_pl10['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                       [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_pl10 = df_pl10.set_index('Amount of added proteins')\n",
    "\n",
    "df_pl15 = pd.DataFrame()\n",
    "df_pl15['Amount of added proteins'], \\\n",
    "df_pl15['alpha = 1'], \\\n",
    "df_pl15['alpha = 2'], \\\n",
    "df_pl15['alpha = 3'], \\\n",
    "df_pl15['alpha = 4'], \\\n",
    "df_pl15['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                       [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_pl15 = df_pl15.set_index('Amount of added proteins')\n",
    "\n",
    "# GO, Reactome and Subcellular location filtering\n",
    "df_gopl5 = pd.DataFrame()\n",
    "df_gopl5['Amount of added proteins'], \\\n",
    "df_gopl5['alpha = 1'], \\\n",
    "df_gopl5['alpha = 2'], \\\n",
    "df_gopl5['alpha = 3'], \\\n",
    "df_gopl5['alpha = 4'], \\\n",
    "df_gopl5['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                        [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_gopl5 = df_gopl5.set_index('Amount of added proteins')\n",
    "\n",
    "df_gopl10 = pd.DataFrame()\n",
    "df_gopl10['Amount of added proteins'], \\\n",
    "df_gopl10['alpha = 1'], \\\n",
    "df_gopl10['alpha = 2'], \\\n",
    "df_gopl10['alpha = 3'], \\\n",
    "df_gopl10['alpha = 4'], \\\n",
    "df_gopl10['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                         [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_gopl10 = df_gopl10.set_index('Amount of added proteins')\n",
    "\n",
    "df_gopl15 = pd.DataFrame()\n",
    "df_gopl15['Amount of added proteins'], \\\n",
    "df_gopl15['alpha = 1'], \\\n",
    "df_gopl15['alpha = 2'], \\\n",
    "df_gopl15['alpha = 3'], \\\n",
    "df_gopl15['alpha = 4'], \\\n",
    "df_gopl15['alpha = 5'] = [ele for ele in x], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], \\\n",
    "                         [0.0 for i in range(len(x))], [0.0 for i in range(len(x))], [0.0 for i in range(len(x))]\n",
    "df_gopl15 = df_gopl15.set_index('Amount of added proteins')\n",
    "\n",
    "# Create the different networks and filtration steps already\n",
    "# No filtration\n",
    "nodes = list(set(list(ppi2.UniprotAccession_A.unique()) + list(ppi2.UniprotAccession_B.unique())))\n",
    "edges = []\n",
    "for i in range(len(ppi2)):\n",
    "    edges.append(tuple([ppi2.UniprotAccession_A[i], ppi2.UniprotAccession_B[i]]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Reactome general filtration\n",
    "uniprot_p = uniprot_ppi.astype(str).reset_index(drop = True)\n",
    "disease_ppi = uniprot_ppi[uniprot_ppi['DisGeNet_disease_name'].str.contains('Breast Carcinoma')].reset_index(drop = True)\n",
    "disease_ppi = disease_ppi[disease_ppi.UniprotAccession.isin(seeds)].reset_index(drop = True)\n",
    "disease_filtered = uniprot_p.copy().reset_index(drop = True)\n",
    "pathways_disease = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.Reactome_ID[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        pathways_disease.add(x[e])\n",
    "pathways_disease = list(pathways_disease)\n",
    "if 'nan' in pathways_disease:\n",
    "    pathways_disease.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(pathways_disease).intersection(disease_filtered.Reactome_ID[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "nodes_disease = disease_filtered.UniprotAccession\n",
    "edges_disease_ppi = pd.DataFrame(ppi2[ppi2['UniprotAccession_A'].isin(nodes_disease) & \\\n",
    "                                      ppi2['UniprotAccession_B'].isin(nodes_disease)])\n",
    "edges_disease_ppi.reset_index(drop=True, inplace = True)\n",
    "edges_disease = []\n",
    "for i in range(len(edges_disease_ppi)):\n",
    "    edges_disease.append(tuple([edges_disease_ppi.UniprotAccession_A[i], edges_disease_ppi.UniprotAccession_B[i]]))\n",
    "\n",
    "G_p = nx.Graph()\n",
    "G_p.add_nodes_from(nodes_disease)\n",
    "G_p.add_edges_from(edges_disease)\n",
    "\n",
    "# Reactome leaf pathway filtration\n",
    "reactome_leaf = pd.read_table(\"https://reactome.org/download/current/UniProt2Reactome.txt\", \n",
    "                                   sep = '\\t', \n",
    "                                   names = ['UniprotAccession',\n",
    "                                            'Reactome_ID', \n",
    "                                            'URL', \n",
    "                                            'Reactome_name', \n",
    "                                            'Evidence Code', \n",
    "                                            'Species'], index_col=False)\n",
    "reactome_leaf = reactome_leaf.astype(str)\n",
    "reactome_leaf = reactome_leaf[reactome_leaf['Species'] == 'Homo sapiens'].reset_index(drop = True)\n",
    "reactome_leaf = reactome_leaf[['UniprotAccession', 'Reactome_ID']]\n",
    "uniprot_lp = uniprot_ppi.astype(str).reset_index(drop = True)\n",
    "disease_ppi = uniprot_ppi[uniprot_ppi['DisGeNet_disease_name'].str.contains('Breast Carcinoma')].reset_index(drop = True)\n",
    "disease_ppi = disease_ppi[disease_ppi.UniprotAccession.isin(seeds)].reset_index(drop = True)\n",
    "disease_filtered = uniprot_lp.copy().reset_index(drop = True)\n",
    "reactome_leaf = reactome_leaf[reactome_leaf['UniprotAccession'].isin(seeds)].drop_duplicates().reset_index(drop = True)\n",
    "leaf_pathways_disease = reactome_leaf.Reactome_ID.unique().tolist()\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(leaf_pathways_disease).intersection(disease_filtered.Reactome_ID[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "nodes_disease = disease_filtered.UniprotAccession\n",
    "edges_disease_ppi = pd.DataFrame(ppi2[ppi2['UniprotAccession_A'].isin(nodes_disease) & \\\n",
    "                                      ppi2['UniprotAccession_B'].isin(nodes_disease)])\n",
    "edges_disease_ppi.reset_index(drop=True, inplace = True)\n",
    "edges_disease = []\n",
    "for i in range(len(edges_disease_ppi)):\n",
    "    edges_disease.append(tuple([edges_disease_ppi.UniprotAccession_A[i], edges_disease_ppi.UniprotAccession_B[i]]))\n",
    "\n",
    "G_lp = nx.Graph()\n",
    "G_lp.add_nodes_from(nodes_disease)\n",
    "G_lp.add_edges_from(edges_disease)\n",
    "\n",
    "# Subcellular Location filtration\n",
    "reactome_leaf = pd.read_table(\"https://reactome.org/download/current/UniProt2Reactome.txt\", \n",
    "                                   sep = '\\t', \n",
    "                                   names = ['UniprotAccession',\n",
    "                                            'Reactome_ID', \n",
    "                                            'URL', \n",
    "                                            'Reactome_name', \n",
    "                                            'Evidence Code', \n",
    "                                            'Species'], index_col=False)\n",
    "reactome_leaf = reactome_leaf.astype(str)\n",
    "reactome_leaf = reactome_leaf[reactome_leaf['Species'] == 'Homo sapiens'].reset_index(drop = True)\n",
    "reactome_leaf = reactome_leaf[['UniprotAccession', 'Reactome_ID']]\n",
    "uniprot_lp = uniprot_ppi.astype(str).reset_index(drop = True)\n",
    "disease_ppi = uniprot_ppi[uniprot_ppi['DisGeNet_disease_name'].str.contains('Breast Carcinoma')].reset_index(drop = True)\n",
    "disease_ppi = disease_ppi[disease_ppi.UniprotAccession.isin(seeds)].reset_index(drop = True)\n",
    "disease_filtered = uniprot_lp.copy().reset_index(drop = True)\n",
    "reactome_leaf = reactome_leaf[reactome_leaf['UniprotAccession'].isin(seeds)].drop_duplicates().reset_index(drop = True)\n",
    "leaf_pathways_disease = reactome_leaf.Reactome_ID.unique().tolist()\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(leaf_pathways_disease).intersection(disease_filtered.Reactome_ID[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "nodes_disease = disease_filtered.UniprotAccession\n",
    "edges_disease_ppi = pd.DataFrame(ppi2[ppi2['UniprotAccession_A'].isin(nodes_disease) & \\\n",
    "                                      ppi2['UniprotAccession_B'].isin(nodes_disease)])\n",
    "edges_disease_ppi.reset_index(drop=True, inplace = True)\n",
    "edges_disease = []\n",
    "for i in range(len(edges_disease_ppi)):\n",
    "    edges_disease.append(tuple([edges_disease_ppi.UniprotAccession_A[i], edges_disease_ppi.UniprotAccession_B[i]]))\n",
    "\n",
    "G_l = nx.Graph()\n",
    "G_l.add_nodes_from(nodes_disease)\n",
    "G_l.add_edges_from(edges_disease)\n",
    "\n",
    "# GO filtration\n",
    "uniprot_go = uniprot_ppi.astype(str).reset_index(drop = True)\n",
    "disease_ppi = uniprot_ppi[uniprot_ppi['DisGeNet_disease_name'].str.contains('Breast Carcinoma')].reset_index(drop = True)\n",
    "disease_ppi = disease_ppi[disease_ppi.UniprotAccession.isin(seeds)].reset_index(drop = True)\n",
    "disease_filtered = uniprot_go.copy().reset_index(drop = True)\n",
    "GObp = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.GO_biological_process[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        GObp.add(x[e])\n",
    "GObp = list(GObp)\n",
    "if 'nan' in GObp:\n",
    "    GObp.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(GObp).intersection(disease_filtered.GO_biological_process[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "GOmf = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.GO_molecular_function[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        GOmf.add(x[e])\n",
    "GOmf = list(GOmf)\n",
    "if 'nan' in GOmf:\n",
    "    GOmf.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(GOmf).intersection(disease_filtered.GO_molecular_function[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "GOcc = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.GO_cellular_component[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        GOcc.add(x[e])\n",
    "GOcc = list(GOcc)\n",
    "if 'nan' in GOcc:\n",
    "    GOcc.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(GOcc).intersection(disease_filtered.GO_cellular_component[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "# Select the protein names and retain only the edges betweeen those nodes\n",
    "nodes_disease = disease_filtered.UniprotAccession\n",
    "edges_disease_ppi = pd.DataFrame(ppi2[ppi2['UniprotAccession_A'].isin(nodes_disease) & \\\n",
    "                                      ppi2['UniprotAccession_B'].isin(nodes_disease)])\n",
    "edges_disease_ppi.reset_index(drop=True, inplace = True)\n",
    "edges_disease = []\n",
    "for i in range(len(edges_disease_ppi)):\n",
    "    edges_disease.append(tuple([edges_disease_ppi.UniprotAccession_A[i], edges_disease_ppi.UniprotAccession_B[i]]))\n",
    "\n",
    "G_go = nx.Graph()\n",
    "G_go.add_nodes_from(nodes_disease)\n",
    "G_go.add_edges_from(edges_disease)\n",
    "\n",
    "# General reactome filtration + subcellular location filtration\n",
    "uniprot_pl = uniprot_ppi.astype(str).reset_index(drop = True)\n",
    "disease_ppi = uniprot_ppi[uniprot_ppi['DisGeNet_disease_name'].str.contains('Breast Carcinoma')].reset_index(drop = True)\n",
    "disease_ppi = disease_ppi[disease_ppi.UniprotAccession.isin(seeds)].reset_index(drop = True)\n",
    "disease_filtered = uniprot_pl.copy().reset_index(drop = True)\n",
    "pathways_disease = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.Reactome_ID[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        pathways_disease.add(x[e])\n",
    "pathways_disease = list(pathways_disease)\n",
    "if 'nan' in pathways_disease:\n",
    "    pathways_disease.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(pathways_disease).intersection(disease_filtered.Reactome_ID[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "location_disease = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.HPA_Subcellular_location[i]).split(',')\n",
    "    for e in range(len(x)):\n",
    "        location_disease.add(x[e])\n",
    "location_disease = list(location_disease)\n",
    "if 'nan' in location_disease:\n",
    "    location_disease.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(set(location_disease).intersection(disease_filtered.HPA_Subcellular_location[i].split(',')))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "nodes_disease = disease_filtered.UniprotAccession\n",
    "edges_disease_ppi = pd.DataFrame(ppi2[ppi2['UniprotAccession_A'].isin(nodes_disease) & \\\n",
    "                                      ppi2['UniprotAccession_B'].isin(nodes_disease)])\n",
    "edges_disease_ppi.reset_index(drop=True, inplace = True)\n",
    "edges_disease = []\n",
    "for i in range(len(edges_disease_ppi)):\n",
    "    edges_disease.append(tuple([edges_disease_ppi.UniprotAccession_A[i], edges_disease_ppi.UniprotAccession_B[i]]))\n",
    "\n",
    "G_pl = nx.Graph()\n",
    "G_pl.add_nodes_from(nodes_disease)\n",
    "G_pl.add_edges_from(edges_disease)\n",
    "\n",
    "# GO, Reactome and Subcellular location filtering\n",
    "uniprot_gopl = uniprot_ppi.astype(str).reset_index(drop = True)\n",
    "disease_ppi = uniprot_ppi[uniprot_ppi['DisGeNet_disease_name'].str.contains('Breast Carcinoma')].reset_index(drop = True)\n",
    "disease_ppi = disease_ppi[disease_ppi.UniprotAccession.isin(seeds)].reset_index(drop = True)\n",
    "disease_filtered = uniprot_gopl.copy().reset_index(drop = True)\n",
    "GObp = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.GO_biological_process[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        GObp.add(x[e])\n",
    "GObp = list(GObp)\n",
    "if 'nan' in GObp:\n",
    "    GObp.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(GObp).intersection(disease_filtered.GO_biological_process[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "GOmf = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.GO_molecular_function[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        GOmf.add(x[e])\n",
    "GOmf = list(GOmf)\n",
    "if 'nan' in GOmf:\n",
    "    GOmf.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(GOmf).intersection(disease_filtered.GO_molecular_function[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "GOcc = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.GO_cellular_component[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        GOcc.add(x[e])\n",
    "GOcc = list(GOcc)\n",
    "if 'nan' in GOcc:\n",
    "    GOcc.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(GOcc).intersection(disease_filtered.GO_cellular_component[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "pathways_disease = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.Reactome_ID[i]).split('; ')\n",
    "    for e in range(len(x)):\n",
    "        pathways_disease.add(x[e])\n",
    "pathways_disease = list(pathways_disease)\n",
    "if 'nan' in pathways_disease:\n",
    "    pathways_disease.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(pathways_disease).intersection(disease_filtered.Reactome_ID[i].split('; '))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "location_disease = set()\n",
    "for i in range(len(disease_ppi)):\n",
    "    x = str(disease_ppi.HPA_Subcellular_location[i]).split(',')\n",
    "    for e in range(len(x)):\n",
    "        location_disease.add(x[e])\n",
    "location_disease = list(location_disease)\n",
    "if 'nan' in location_disease:\n",
    "    location_disease.remove('nan')\n",
    "for i in range(disease_filtered.shape[0]):\n",
    "    if len(set(set(location_disease).intersection(disease_filtered.HPA_Subcellular_location[i].split(',')))) == 0:\n",
    "        disease_filtered.drop([i], inplace = True)\n",
    "disease_filtered.reset_index(drop=True, inplace = True)\n",
    "nodes_disease = disease_filtered.UniprotAccession\n",
    "edges_disease_ppi = pd.DataFrame(ppi2[ppi2['UniprotAccession_A'].isin(nodes_disease) & \\\n",
    "                                      ppi2['UniprotAccession_B'].isin(nodes_disease)])\n",
    "edges_disease_ppi.reset_index(drop=True, inplace = True)\n",
    "edges_disease = []\n",
    "for i in range(len(edges_disease_ppi)):\n",
    "    edges_disease.append(tuple([edges_disease_ppi.UniprotAccession_A[i], edges_disease_ppi.UniprotAccession_B[i]]))\n",
    "\n",
    "G_gopl = nx.Graph()\n",
    "G_gopl.add_nodes_from(nodes_disease)\n",
    "G_gopl.add_edges_from(edges_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat all steps 20 times and get an average of the 20 times by the end\n",
    "for _ in range(10):\n",
    "    seeds1 = random.sample(seeds, len(seeds)-5)\n",
    "    seeds2 = random.sample(seeds1, len(seeds)-10)\n",
    "    seeds3 = random.sample(seeds2, len(seeds)-15)\n",
    "    \n",
    "    x = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
    "    \n",
    "    # No Filtration\n",
    "    for ele in x:\n",
    "        for i in range(1, 6):\n",
    "            added_nodes5 = set()\n",
    "            added_nodes10 = set()\n",
    "            added_nodes15 = set()\n",
    "            algo5 = DIAMOnD(G_original = G, seed_genes = seeds1, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random5.csv')\n",
    "            algo10 = DIAMOnD(G_original = G, seed_genes = seeds2, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random10.csv')\n",
    "            algo15 = DIAMOnD(G_original = G, seed_genes = seeds3, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random15.csv')\n",
    "            for e in range(ele):\n",
    "                added_nodes5.add(algo5[e][0])\n",
    "                added_nodes10.add(algo10[e][0])\n",
    "                added_nodes15.add(algo15[e][0])\n",
    "            seeds_intersect5 = set(added_nodes5.intersection(seeds))\n",
    "            seeds_intersect10 = set(added_nodes10.intersection(seeds))\n",
    "            seeds_intersect15 = set(added_nodes15.intersection(seeds))\n",
    "            df_5[f'alpha = {i}'][ele] += round(len(seeds_intersect5)/5 * 100, 2)\n",
    "            df_10[f'alpha = {i}'][ele] += round(len(seeds_intersect10)/10 * 100, 2)\n",
    "            df_15[f'alpha = {i}'][ele] += round(len(seeds_intersect15)/15 * 100, 2)\n",
    "    \n",
    "    # Reactome general filtration\n",
    "    for ele in x:\n",
    "        for i in range(1, 6):\n",
    "            added_nodes5 = set()\n",
    "            added_nodes10 = set()\n",
    "            added_nodes15 = set()\n",
    "            algo5 = DIAMOnD(G_original = G_p, seed_genes = seeds1, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random5.csv')\n",
    "            algo10 = DIAMOnD(G_original = G_p, seed_genes = seeds2, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random10.csv')\n",
    "            algo15 = DIAMOnD(G_original = G_p, seed_genes = seeds3, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random15.csv')\n",
    "            for e in range(ele):\n",
    "                added_nodes5.add(algo5[e][0])\n",
    "                added_nodes10.add(algo10[e][0])\n",
    "                added_nodes15.add(algo15[e][0])\n",
    "            seeds_intersect5 = set(added_nodes5.intersection(seeds))\n",
    "            seeds_intersect10 = set(added_nodes10.intersection(seeds))\n",
    "            seeds_intersect15 = set(added_nodes15.intersection(seeds))\n",
    "            df_p5[f'alpha = {i}'][ele] += round(len(seeds_intersect5)/5 * 100, 2)\n",
    "            df_p10[f'alpha = {i}'][ele] += round(len(seeds_intersect10)/10 * 100, 2)\n",
    "            df_p15[f'alpha = {i}'][ele] += round(len(seeds_intersect15)/15 * 100, 2)\n",
    "    \n",
    "    # Reactome leaf pathway filtration\n",
    "    for ele in x:\n",
    "        for i in range(1, 6):\n",
    "            added_nodes5 = set()\n",
    "            added_nodes10 = set()\n",
    "            added_nodes15 = set()\n",
    "            algo5 = DIAMOnD(G_original = G_lp, seed_genes = seeds1, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random5.csv')\n",
    "            algo10 = DIAMOnD(G_original = G_lp, seed_genes = seeds2, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random10.csv')\n",
    "            algo15 = DIAMOnD(G_original = G_lp, seed_genes = seeds3, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random15.csv')\n",
    "            for e in range(ele):\n",
    "                added_nodes5.add(algo5[e][0])\n",
    "                added_nodes10.add(algo10[e][0])\n",
    "                added_nodes15.add(algo15[e][0])\n",
    "            seeds_intersect5 = set(added_nodes5.intersection(seeds))\n",
    "            seeds_intersect10 = set(added_nodes10.intersection(seeds))\n",
    "            seeds_intersect15 = set(added_nodes15.intersection(seeds))\n",
    "            df_lp5[f'alpha = {i}'][ele] += round(len(seeds_intersect5)/5 * 100, 2)\n",
    "            df_lp10[f'alpha = {i}'][ele] += round(len(seeds_intersect10)/10 * 100, 2)\n",
    "            df_lp15[f'alpha = {i}'][ele] += round(len(seeds_intersect15)/15 * 100, 2)\n",
    "    \n",
    "    # Subcellular location filtration\n",
    "    for ele in x:\n",
    "        for i in range(1, 6):\n",
    "            added_nodes5 = set()\n",
    "            added_nodes10 = set()\n",
    "            added_nodes15 = set()\n",
    "            algo5 = DIAMOnD(G_original = G_l, seed_genes = seeds1, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random5.csv')\n",
    "            algo10 = DIAMOnD(G_original = G_l, seed_genes = seeds2, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random10.csv')\n",
    "            algo15 = DIAMOnD(G_original = G_l, seed_genes = seeds3, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random15.csv')\n",
    "            for e in range(ele):\n",
    "                added_nodes5.add(algo5[e][0])\n",
    "                added_nodes10.add(algo10[e][0])\n",
    "                added_nodes15.add(algo15[e][0])\n",
    "            seeds_intersect5 = set(added_nodes5.intersection(seeds))\n",
    "            seeds_intersect10 = set(added_nodes10.intersection(seeds))\n",
    "            seeds_intersect15 = set(added_nodes15.intersection(seeds))\n",
    "            df_l5[f'alpha = {i}'][ele] += round(len(seeds_intersect5)/5 * 100, 2)\n",
    "            df_l10[f'alpha = {i}'][ele] += round(len(seeds_intersect10)/10 * 100, 2)\n",
    "            df_l15[f'alpha = {i}'][ele] += round(len(seeds_intersect15)/15 * 100, 2)\n",
    "    \n",
    "    # GO filtration\n",
    "    for ele in x:\n",
    "        for i in range(1, 6):\n",
    "            added_nodes5 = set()\n",
    "            added_nodes10 = set()\n",
    "            added_nodes15 = set()\n",
    "            algo5 = DIAMOnD(G_original = G_go, seed_genes = seeds1, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random5.csv')\n",
    "            algo10 = DIAMOnD(G_original = G_go, seed_genes = seeds2, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random10.csv')\n",
    "            algo15 = DIAMOnD(G_original = G_go, seed_genes = seeds3, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random15.csv')\n",
    "            for e in range(ele):\n",
    "                added_nodes5.add(algo5[e][0])\n",
    "                added_nodes10.add(algo10[e][0])\n",
    "                added_nodes15.add(algo15[e][0])\n",
    "            seeds_intersect5 = set(added_nodes5.intersection(seeds))\n",
    "            seeds_intersect10 = set(added_nodes10.intersection(seeds))\n",
    "            seeds_intersect15 = set(added_nodes15.intersection(seeds))\n",
    "            df_go5[f'alpha = {i}'][ele] += round(len(seeds_intersect5)/5 * 100, 2)\n",
    "            df_go10[f'alpha = {i}'][ele] += round(len(seeds_intersect10)/10 * 100, 2)\n",
    "            df_go15[f'alpha = {i}'][ele] += round(len(seeds_intersect15)/15 * 100, 2)\n",
    "    \n",
    "    # General reactome filtration + subcellular location filtration\n",
    "    for ele in x:\n",
    "        for i in range(1, 6):\n",
    "            added_nodes5 = set()\n",
    "            added_nodes10 = set()\n",
    "            added_nodes15 = set()\n",
    "            algo5 = DIAMOnD(G_original = G_pl, seed_genes = seeds1, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random5.csv')\n",
    "            algo10 = DIAMOnD(G_original = G_pl, seed_genes = seeds2, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random10.csv')\n",
    "            algo15 = DIAMOnD(G_original = G_pl, seed_genes = seeds3, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random15.csv')\n",
    "            for e in range(ele):\n",
    "                added_nodes5.add(algo5[e][0])\n",
    "                added_nodes10.add(algo10[e][0])\n",
    "                added_nodes15.add(algo15[e][0])\n",
    "            seeds_intersect5 = set(added_nodes5.intersection(seeds))\n",
    "            seeds_intersect10 = set(added_nodes10.intersection(seeds))\n",
    "            seeds_intersect15 = set(added_nodes15.intersection(seeds))\n",
    "            df_pl5[f'alpha = {i}'][ele] += round(len(seeds_intersect5)/5 * 100, 2)\n",
    "            df_pl10[f'alpha = {i}'][ele] += round(len(seeds_intersect10)/10 * 100, 2)\n",
    "            df_pl15[f'alpha = {i}'][ele] += round(len(seeds_intersect15)/15 * 100, 2)\n",
    "    \n",
    "    # GO, Reactome and Subcellular location filtering\n",
    "    for ele in x:\n",
    "        for i in range(1, 6):\n",
    "            added_nodes5 = set()\n",
    "            added_nodes10 = set()\n",
    "            added_nodes15 = set()\n",
    "            algo5 = DIAMOnD(G_original = G_gopl, seed_genes = seeds1, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random5.csv')\n",
    "            algo10 = DIAMOnD(G_original = G_gopl, seed_genes = seeds2, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random10.csv')\n",
    "            algo15 = DIAMOnD(G_original = G_gopl, seed_genes = seeds3, max_number_of_added_nodes = ele, alpha = i, outfile = 'BC_added_nodes_random15.csv')\n",
    "            for e in range(ele):\n",
    "                added_nodes5.add(algo5[e][0])\n",
    "                added_nodes10.add(algo10[e][0])\n",
    "                added_nodes15.add(algo15[e][0])\n",
    "            seeds_intersect5 = set(added_nodes5.intersection(seeds))\n",
    "            seeds_intersect10 = set(added_nodes10.intersection(seeds))\n",
    "            seeds_intersect15 = set(added_nodes15.intersection(seeds))\n",
    "            df_gopl5[f'alpha = {i}'][ele] += round(len(seeds_intersect5)/5 * 100, 2)\n",
    "            df_gopl10[f'alpha = {i}'][ele] += round(len(seeds_intersect10)/10 * 100, 2)\n",
    "            df_gopl15[f'alpha = {i}'][ele] += round(len(seeds_intersect15)/15 * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the average of the 20 repititions\n",
    "# No filtration\n",
    "df_5 = df_5/10\n",
    "df_5 = df_5.round(2)\n",
    "df_10 = df_10/10\n",
    "df_10 = df_10.round(2)\n",
    "df_15 = df_15/10\n",
    "df_15 = df_15.round(2)\n",
    "\n",
    "# Reactome general filtration\n",
    "df_p5 = df_p5/10\n",
    "df_p5 = df_p5.round(2)\n",
    "df_p10 = df_p10/10\n",
    "df_p10 = df_p10.round(2)\n",
    "df_p15 = df_p15/10\n",
    "df_p15 = df_p15.round(2)\n",
    "\n",
    "# Reactome leaf pathway filtration\n",
    "df_lp5 = df_lp5/10\n",
    "df_lp5 = df_lp5.round(2)\n",
    "df_lp10 = df_lp10/10\n",
    "df_lp10 = df_lp10.round(2)\n",
    "df_lp15 = df_lp15/10\n",
    "df_lp15 = df_lp15.round(2)\n",
    "\n",
    "# Subcellular location filtration\n",
    "df_l5 = df_l5/10\n",
    "df_l5 = df_l5.round(2)\n",
    "df_l10 = df_l10/10\n",
    "df_l10 = df_l10.round(2)\n",
    "df_l15 = df_l15/10\n",
    "df_l15 = df_l15.round(2)\n",
    "\n",
    "# GO filtration\n",
    "df_go5 = df_go5/10\n",
    "df_go5 = df_go5.round(2)\n",
    "df_go10 = df_go10/10\n",
    "df_go10 = df_go10.round(2)\n",
    "df_go15 = df_go15/10\n",
    "df_go15 = df_go15.round(2)\n",
    "\n",
    "# General reactome filtration + subcellular location filtration\n",
    "df_pl5 = df_pl5/10\n",
    "df_pl5 = df_pl5.round(2)\n",
    "df_pl10 = df_pl10/10\n",
    "df_pl10 = df_pl10.round(2)\n",
    "df_pl15 = df_pl15/10\n",
    "df_pl15 = df_pl15.round(2)\n",
    "\n",
    "# GO, Reactome and Subcellular location filtering\n",
    "df_gopl5 = df_gopl5/10\n",
    "df_gopl5 = df_gopl5.round(2)\n",
    "df_gopl10 = df_gopl10/10\n",
    "df_gopl10 = df_gopl10.round(2)\n",
    "df_gopl15 = df_gopl15/10\n",
    "df_gopl15 = df_gopl15.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No filtration\n",
    "df_5.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_No_Filtration_5.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_10.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_No_Filtration_10.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_15.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_No_Filtration_15.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "\n",
    "# Reactome general filtration\n",
    "df_p5.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Reactome_general_5.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_p10.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Reactome_general_10.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_p15.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Reactome_general_15.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "\n",
    "# Reactome leaf pathway filtration\n",
    "df_lp5.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Reactome_leaf_5.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_lp10.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Reactome_leaf_10.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_lp15.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Reactome_leaf_15.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "\n",
    "# Subcellular location filtration\n",
    "df_l5.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Subcellular_location_5.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_l10.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Subcellular_location_10.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_l15.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Subcellular_location_15.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "\n",
    "# GO filtration\n",
    "df_go5.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_GO_5.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_go10.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_GO_10.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_go15.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_GO_15.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "\n",
    "# General reactome filtration + subcellular location filtration\n",
    "df_pl5.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Pathway_subcellular_location_5.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_pl10.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Pathway_subcellular_location_10.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_pl15.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_Pathway_subcellular_location_15.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "\n",
    "# GO, Reactome and Subcellular location filtering\n",
    "df_gopl5.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_GO_Pathway_subcellular_location_5.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_gopl10.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_GO_Pathway_subcellular_location_10.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "df_gopl15.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Figures\\\\10_2_GO_Pathway_subcellular_location_15.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
