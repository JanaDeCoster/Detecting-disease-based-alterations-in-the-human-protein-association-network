{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : b5958ee1999e9aead1938c0bba2b674378807b3d\n",
      "python           : 3.8.3.final.0\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "Version          : 10.0.19041\n",
      "machine          : AMD64\n",
      "processor        : Intel64 Family 6 Model 78 Stepping 3, GenuineIntel\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : Dutch_Belgium.1252\n",
      "\n",
      "pandas           : 1.1.5\n",
      "numpy            : 1.18.5\n",
      "pytz             : 2020.1\n",
      "dateutil         : 2.8.1\n",
      "pip              : 20.1.1\n",
      "setuptools       : 49.2.0.post20200714\n",
      "Cython           : 0.29.14\n",
      "pytest           : 5.4.3\n",
      "hypothesis       : None\n",
      "sphinx           : 3.1.2\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : 1.2.9\n",
      "lxml.etree       : 4.5.2\n",
      "html5lib         : 1.1\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 2.11.2\n",
      "IPython          : 7.16.1\n",
      "pandas_datareader: None\n",
      "bs4              : 4.9.1\n",
      "bottleneck       : 1.3.2\n",
      "fsspec           : 0.7.4\n",
      "fastparquet      : None\n",
      "gcsfs            : None\n",
      "matplotlib       : 3.2.2\n",
      "numexpr          : 2.7.1\n",
      "odfpy            : None\n",
      "openpyxl         : 3.0.4\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pytables         : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.5.0\n",
      "sqlalchemy       : 1.3.18\n",
      "tables           : 3.6.1\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : 1.2.0\n",
      "xlwt             : 1.3.0\n",
      "numba            : 0.50.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import functools\n",
    "import itertools\n",
    "import community as community_louvain\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from networkx.algorithms import community\n",
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRING Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data and create a STRING dataframe\n",
    "string1 = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\9606.protein.links.full.v11.0.txt.gz', compression='gzip', header=0, sep=' ')\n",
    "string1 = pd.DataFrame(string1)\n",
    "string = string1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of original inetractions: 11759454\n",
      "The amount of original proteins: 19354\n"
     ]
    }
   ],
   "source": [
    "print(f'The amount of original inetractions: {string.shape[0]}')\n",
    "print(f'The amount of original proteins: {len(set(string.protein1.tolist() + string.protein2.tolist()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain the most necessary columns and \n",
    "# create a column named 'Database' to know which database contained which interaction\n",
    "string = string[['protein1', 'protein2', 'combined_score']]\n",
    "string['Database_S'] = 'S'\n",
    "\n",
    "# Remove all duplicated protein pairs\n",
    "string['sorted_row'] = [sorted([a,b]) for a,b in zip(string.protein1, string.protein2)]\n",
    "string['sorted_row'] = string['sorted_row'].astype(str)\n",
    "string.drop_duplicates(subset=['sorted_row'], inplace=True)\n",
    "string = string.drop(columns = ['sorted_row'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all the uniprot ID's and match them with the STRING protein ID's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the STRING protein ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein 1 column\n",
    "names1 = string['protein1'].unique()\n",
    "string_names_protein1 = names1.tolist()\n",
    "f = open('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\string_names_protein1.txt','w')\n",
    "f.write('\\n'.join(string_names_protein1))\n",
    "f.close()\n",
    "\n",
    "# Protein 2 column\n",
    "names2 = string['protein2'].unique()\n",
    "string_names_protein2 = names2.tolist()\n",
    "f = open('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\string_names_protein2.txt','w')\n",
    "f.write('\\n'.join(string_names_protein2))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein 1 column\n",
    "uniprot_string_protein1 = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\uniprot-protein1.tab.gz', compression='gzip', sep = '\\t')\n",
    "uniprot_string_protein1.rename(columns = {'yourlist:M20201112E5A08BB0B2D1C45B0C7BC3B55FD2655603E3E1X':'protein', \n",
    "                                          'Entry':'UniProtKB_ID'}, inplace=True)\n",
    "uniprot_string_protein1 = uniprot_string_protein1[['protein', 'UniProtKB_ID']]\n",
    "\n",
    "# Protein 2 column\n",
    "uniprot_string_protein2 = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\uniprot-protein2.tab.gz', compression='gzip', sep = '\\t')\n",
    "uniprot_string_protein2.rename(columns = {'yourlist:M20201112216DA2B77BFBD2E6699CA9B6D1C41EB203E4D3V':'protein', \n",
    "                                          'Entry':'UniProtKB_ID'}, inplace=True)\n",
    "uniprot_string_protein2 = uniprot_string_protein2[['protein', 'UniProtKB_ID']]\n",
    "\n",
    "# Combine into one dataframe\n",
    "uniprot_string = pd.concat([uniprot_string_protein1, uniprot_string_protein2])\n",
    "uniprot_string = uniprot_string.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18501, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniprot_string.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_string.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\US_IDs.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the UniProt ID's with the STRING dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Uniprot IDs together with the STRING IDs\n",
    "string_uniprot1 = pd.merge(string, uniprot_string, left_on='protein1', right_on='protein')\n",
    "string_uniprot2 = pd.merge(string_uniprot1, uniprot_string, left_on='protein2', right_on='protein')\n",
    "string_uniprot2 = string_uniprot2[['UniProtKB_ID_x', \n",
    "                                   'UniProtKB_ID_y', \n",
    "                                   'protein_x', \n",
    "                                   'protein_y', \n",
    "                                   'Database_S', \n",
    "                                   'combined_score']]\n",
    "\n",
    "# Rename the columns\n",
    "string_uniprot2.rename(columns = {'UniProtKB_ID_x' : 'UniprotAccessionA', \n",
    "                                  'UniProtKB_ID_y' : 'UniprotAccessionB', \n",
    "                                  'protein_x' : 'STRING_IDA',\n",
    "                                  'protein_y' : 'STRING_IDB', \n",
    "                                  'combined_score' : 'STRING_score'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the IDs so later te merging will happen on the same interaction pairs and create a new dataframe out of it\n",
    "ids = [sorted([a,b]) for a,b in zip(string_uniprot2.UniprotAccessionA, string_uniprot2.UniprotAccessionB)]\n",
    "d = {'UniprotAccessionA' : [ids[i][0] for i in range(len(ids))], \n",
    "     'UniprotAccessionB' : [ids[i][1] for i in range(len(ids))], \n",
    "     'Database_S' : string_uniprot2.Database_S, \n",
    "     'STRING_score': string_uniprot2.STRING_score}\n",
    "string_uniprot3 = pd.DataFrame(data=d)\n",
    "string_uniprot4 = pd.merge(string_uniprot3, uniprot_string, left_on='UniprotAccessionA', right_on='UniProtKB_ID')\n",
    "string_uniprot = pd.merge(string_uniprot4, uniprot_string, left_on='UniprotAccessionB', right_on='UniProtKB_ID')\n",
    "\n",
    "# Retain the correct columns\n",
    "string_uniprot = string_uniprot[['UniprotAccessionA', \n",
    "                                 'UniprotAccessionB', \n",
    "                                 'protein_x', \n",
    "                                 'protein_y', \n",
    "                                 'Database_S', \n",
    "                                 'STRING_score']]\n",
    "\n",
    "# Rename the columns\n",
    "string_uniprot.rename(columns = {'protein_x' : 'STRING_IDA',\n",
    "                                 'protein_y' : 'STRING_IDB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5538412, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_uniprot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_uniprot.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\STRING_UniProt.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioGRID Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data and create a BioGRID dataframe\n",
    "biogrid1 = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\BIOGRID-ORGANISM-Homo_sapiens-3.5.188.tab3.txt', delimiter='\\t', low_memory = False)\n",
    "biogrid1 = pd.DataFrame(biogrid1)\n",
    "biogrid = biogrid1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of original inetractions: 616492\n",
      "The amount of original proteins: 25772\n"
     ]
    }
   ],
   "source": [
    "print(f'The amount of original inetractions: {biogrid.shape[0]}')\n",
    "x = len(set(list(biogrid['BioGRID ID Interactor A']) + list(biogrid['BioGRID ID Interactor B'])))\n",
    "print(f'The amount of original proteins: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain the most necessary columns and \n",
    "# create a column named 'Database' to know which database contained which interaction\n",
    "biogrid = biogrid[['BioGRID ID Interactor A', \n",
    "                   'BioGRID ID Interactor B', \n",
    "                   'Score', \n",
    "                   'Ontology Term IDs']]\n",
    "biogrid['Database_B'] = 'B'\n",
    "\n",
    "# Turn the type of the columns to strings\n",
    "biogrid = biogrid.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all the uniprot ID's and match them with the BioGRID protein ID's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the BioGRID protein ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioGRID ID Interactor A column\n",
    "names11 = biogrid['BioGRID ID Interactor A'].unique()\n",
    "biogrid_names_interactora = names11.tolist()\n",
    "f = open('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\biogrid_names_interactorA.txt','w')\n",
    "f.write('\\n'.join(biogrid_names_interactora))\n",
    "f.close()\n",
    "\n",
    "# BioGRID ID Interactor B column\n",
    "names22 = biogrid['BioGRID ID Interactor B'].unique()\n",
    "biogrid_names_interactorb = names22.tolist()\n",
    "f = open('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\biogrid_names_interactorB.txt','w')\n",
    "f.write('\\n'.join(biogrid_names_interactorb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioGRID ID Interactor A column\n",
    "uniprot_biogrid_interactora = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\uniprot-interactorA.tab.gz', compression='gzip', sep = '\\t')\n",
    "uniprot_biogrid_interactora.rename(columns = {'yourlist:M202011128471C63D39733769F8E060B506551E120428BAB':'BioGRID_ID', \n",
    "                                              'Entry':'UniProtKB_ID'}, inplace=True)\n",
    "uniprot_biogrid_interactora = uniprot_biogrid_interactora.loc[:, ['BioGRID_ID', \n",
    "                                                                  'UniProtKB_ID']]\n",
    "\n",
    "# BioGRID ID Interactor B column\n",
    "uniprot_biogrid_interactorb = pd.read_csv(r'D:\\\\Jana De Coster\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\uniprot-interactorB.tab.gz', compression='gzip', sep = '\\t')\n",
    "uniprot_biogrid_interactorb.rename(columns = {'yourlist:M202011128471C63D39733769F8E060B506551E120428AF2':'BioGRID_ID', \n",
    "                                              'Entry':'UniProtKB_ID'}, inplace=True)\n",
    "uniprot_biogrid_interactorb = uniprot_biogrid_interactorb.loc[:, ['BioGRID_ID', \n",
    "                                                                  'UniProtKB_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17222, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into one dataframe\n",
    "uniprot_biogrid = pd.concat([uniprot_biogrid_interactora, uniprot_biogrid_interactorb])\n",
    "uniprot_biogrid = uniprot_biogrid.drop_duplicates()\n",
    "uniprot_biogrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_biogrid.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\UB_IDs.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the UniProt ID's with the BioGRID dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Uniprot IDs together with the BioGRID IDs\n",
    "biogrid_uniprot1 = pd.merge(biogrid, uniprot_biogrid, left_on = 'BioGRID ID Interactor A', right_on = 'BioGRID_ID')\n",
    "biogrid_uniprot2 = pd.merge(biogrid_uniprot1, uniprot_biogrid, left_on = 'BioGRID ID Interactor B', right_on = 'BioGRID_ID')\n",
    "biogrid_uniprot2 = biogrid_uniprot2[['UniProtKB_ID_x', \n",
    "                                     'UniProtKB_ID_y', \n",
    "                                     'BioGRID_ID_x', \n",
    "                                     'BioGRID_ID_y', \n",
    "                                     'Database_B', \n",
    "                                     'Score', \n",
    "                                     'Ontology Term IDs']]\n",
    "\n",
    "# Rename the columns\n",
    "biogrid_uniprot2.rename(columns = {'UniProtKB_ID_x' : 'UniprotAccessionA', \n",
    "                                   'UniProtKB_ID_y' : 'UniprotAccessionB', \n",
    "                                   'BioGRID_ID_x' : 'BioGRID_IDA',\n",
    "                                   'BioGRID_ID_y' : 'BioGRID_IDB', \n",
    "                                   'Score' : 'BioGRID_score', \n",
    "                                   'Ontology Term IDs' : 'BioGRID_ontology_ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the IDs so later te merging will happen on the same interaction pairs and create a new dataframe out of it\n",
    "ids = [sorted([a,b]) for a,b in zip(biogrid_uniprot2.UniprotAccessionA, biogrid_uniprot2.UniprotAccessionB)]\n",
    "d = {'UniprotAccessionA' : [ids[i][0] for i in range(len(ids))], \n",
    "     'UniprotAccessionB' : [ids[i][1] for i in range(len(ids))], \n",
    "     'Database_B' : biogrid_uniprot2.Database_B, \n",
    "     'BioGRID_score' : biogrid_uniprot2.BioGRID_score, \n",
    "     'BioGRID_ontology_ID' : biogrid_uniprot2.BioGRID_ontology_ID}\n",
    "biogrid_uniprot3 = pd.DataFrame(data=d)\n",
    "biogrid_uniprot4 = pd.merge(biogrid_uniprot3, uniprot_biogrid, left_on='UniprotAccessionA', right_on='UniProtKB_ID')\n",
    "biogrid_uniprot = pd.merge(biogrid_uniprot4, uniprot_biogrid, left_on='UniprotAccessionB', right_on='UniProtKB_ID')\n",
    "\n",
    "# Retain the correct columns\n",
    "biogrid_uniprot = biogrid_uniprot[['UniprotAccessionA', \n",
    "                                   'UniprotAccessionB', \n",
    "                                   'BioGRID_ID_x', \n",
    "                                   'BioGRID_ID_y', \n",
    "                                   'Database_B', \n",
    "                                   'BioGRID_score', \n",
    "                                   'BioGRID_ontology_ID']]\n",
    "\n",
    "# Rename the columns\n",
    "biogrid_uniprot.rename(columns = {'BioGRID_ID_x' : 'BioGRID_IDA',\n",
    "                                  'BioGRID_ID_y' : 'BioGRID_IDB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560450, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biogrid_uniprot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "biogrid_uniprot.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\BioGRID_UniProt.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntAct Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data and create a IntAct dataframe\n",
    "intact1 = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\species__H.txt', delimiter='\\t')\n",
    "intact1 = pd.DataFrame(intact1)\n",
    "intact = intact1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of original inetractions: 628794\n",
      "The amount of original proteins: 41810\n"
     ]
    }
   ],
   "source": [
    "print(f'The amount of original inetractions: {intact.shape[0]}')\n",
    "x = len(set(list(intact['#ID(s) interactor A']) + list(intact['ID(s) interactor B'])))\n",
    "print(f'The amount of original proteins: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain the most necessary columns and \n",
    "# create a column named 'Database' to know which database contained which interaction\n",
    "intact = intact[['#ID(s) interactor A',\n",
    "                 'ID(s) interactor B', \n",
    "                 'Confidence value(s)']]\n",
    "intact['Database_I'] = 'I'\n",
    "\n",
    "#Rename the columns\n",
    "intact.rename(columns = {'#ID(s) interactor A' : 'UniprotAccessionA',\n",
    "                         'ID(s) interactor B' : 'UniprotAccessionB', \n",
    "                         'Confidence value(s)' : 'IntAct_score'}, inplace=True)\n",
    "\n",
    "# Remove prefixes in the columns 'UniprotAccessionA', 'UniprotAccessionB' and 'IntAct_score'\n",
    "intact['UniprotAccessionA'] = intact['UniprotAccessionA'].str.replace('uniprotkb:', '')\n",
    "intact['UniprotAccessionB'] = intact['UniprotAccessionB'].str.replace('uniprotkb:', '')\n",
    "intact['IntAct_score'] = intact['IntAct_score'].str.replace('intact-miscore:', '')\n",
    "\n",
    "# Make the IntAct score a numeric value\n",
    "intact['IntAct_score'] = pd.to_numeric(intact['IntAct_score'], errors='coerce')\n",
    "\n",
    "# Only retain the ID's that are reviewed in UniProt\n",
    "uniprot1 = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\uniprot_homo_sapiens_reviewed.tab.gz', compression='gzip', sep = '\\t')\n",
    "uniprot = uniprot1['Entry'].tolist()\n",
    "intact = intact[intact.UniprotAccessionA.isin(uniprot)]\n",
    "intact = intact[intact.UniprotAccessionB.isin(uniprot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the IDs so later te merging will happen on the same interaction pairs and create a new dataframe out of it\n",
    "ids = [sorted([a,b]) for a,b in zip(intact.UniprotAccessionA, intact.UniprotAccessionB)]\n",
    "d = {'UniprotAccessionA' : [ids[i][0] for i in range(len(ids))], \n",
    "     'UniprotAccessionB' : [ids[i][1] for i in range(len(ids))], \n",
    "     'Database_I' : intact.Database_I, \n",
    "     'IntAct_score' : intact.IntAct_score}\n",
    "intact_uniprot = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394598, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intact_uniprot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "intact_uniprot.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\IntAct_UniProt.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all the PPI dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6584525, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the three dataframes together based on the UniProt IDs an dremove the rows that contain the same protein twice\n",
    "sb = pd.merge(string_uniprot, biogrid_uniprot, how = 'outer', on = ['UniprotAccessionA', 'UniprotAccessionB'])\n",
    "ppi_all = pd.merge(sb, intact_uniprot, how = 'outer', on = ['UniprotAccessionA', 'UniprotAccessionB'])\n",
    "ppi_all = ppi_all.loc[ppi_all['UniprotAccessionA'] != ppi_all['UniprotAccessionB']]\n",
    "ppi_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6584525, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the database origin into one column\n",
    "ppi_all['Database_S'] = ppi_all['Database_S'].fillna('')\n",
    "ppi_all['Database_B'] = ppi_all['Database_B'].fillna('')\n",
    "ppi_all['Database_I'] = ppi_all['Database_I'].fillna('')\n",
    "ppi_all['Database'] = ppi_all['Database_I'] + ppi_all['Database_B'] + ppi_all['Database_S']\n",
    "\n",
    "# Readjust the columns\n",
    "ppi_all = ppi_all[['UniprotAccessionA', \n",
    "                   'UniprotAccessionB', \n",
    "                   'BioGRID_IDA', \n",
    "                   'BioGRID_IDB', \n",
    "                   'STRING_IDA', \n",
    "                   'STRING_IDB',\n",
    "                   'Database', \n",
    "                   'IntAct_score', \n",
    "                   'BioGRID_score', \n",
    "                   'STRING_score', \n",
    "                   'BioGRID_ontology_ID']]\n",
    "ppi_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "ppi_all.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI_data.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the PPI dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_all = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI_data.csv', low_memory = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First adjust the STRING score to get a value between 0 and 1\n",
    "ppi_all['STRING_score'] = ppi_all['STRING_score'] / 1000\n",
    "\n",
    "# Filter the PPI data based on preset values:\n",
    "# STRING scores should be above 0. OR Intact scores should be above 0.4\n",
    "# BioGRID scores are filtered based on having a confidence score since these scores are derived based on different methods\n",
    "\n",
    "ppi = ppi_all[((ppi_all['STRING_score'] >= 0.55) \n",
    "              & (ppi_all['BioGRID_score'] != '-'))\n",
    "              | ((ppi_all['IntAct_score'] >= 0.40)\n",
    "              & (ppi_all['BioGRID_score'] != '-'))\n",
    "              | ((ppi_all['IntAct_score'] >= 0.40)\n",
    "              & (ppi_all['STRING_score'] >= 0.55)\n",
    "              & (ppi_all['BioGRID_score'] != '-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(611761, 11)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S      494765\n",
       "IBS     61480\n",
       "BS      20903\n",
       "IS      20379\n",
       "I       12055\n",
       "IB       2179\n",
       "Name: Database, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppi['Database'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI_data_filtered.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_data = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\uniprot_homo_sapiens_reviewed.tab.gz', compression='gzip', sep = '\\t')\n",
    "\n",
    "# Retain only the necessary columns and change their names\n",
    "go_data = go_data[['Entry', \n",
    "                   'Protein names', \n",
    "                   'Gene names', \n",
    "                   'Gene ontology (biological process)', \n",
    "                   'Gene ontology (cellular component)', \n",
    "                   'Gene ontology (molecular function)']]\n",
    "go_data.rename(columns = {'Entry' : 'UniprotAccession',\n",
    "                          'Protein names' : 'Protein_name', \n",
    "                          'Gene names' : 'Gene_names', \n",
    "                          'Gene ontology (biological process)' : 'GO_biological_process', \n",
    "                          'Gene ontology (cellular component)' : 'GO_cellular_component', \n",
    "                          'Gene ontology (molecular function)' : 'GO_molecular_function'}, inplace = True)\n",
    "\n",
    "# Save the dataframe\n",
    "go_data.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\GO_data.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactome Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_data = pd.read_table(\"https://reactome.org/download/current/UniProt2Reactome_All_Levels.txt\", \n",
    "                              sep = '\\t', names = ['UniProtID',\n",
    "                                                   'Reactome Pathway Stable identifier',\n",
    "                                                   'URL',\n",
    "                                                   'Event (Pathway or Reaction) Name',\n",
    "                                                   'Evidence Code',\n",
    "                                                   'Species'])\n",
    "# Select only human related pathways\n",
    "reactome_data = reactome_data[reactome_data['Species'] == 'Homo sapiens']\n",
    "\n",
    "# Retain only the necessary columns and change their names\n",
    "reactome_data = reactome_data[['UniProtID', \n",
    "                               'Reactome Pathway Stable identifier', \n",
    "                               'Event (Pathway or Reaction) Name']]\n",
    "reactome_data.rename(columns = {'UniProtID' : 'UniprotAccession', \n",
    "                                'Reactome Pathway Stable identifier' : 'Reactome_ID',\n",
    "                                'Event (Pathway or Reaction) Name' : 'Reactome_name'}, inplace = True)\n",
    "\n",
    "# Organize per UniProt ID\n",
    "reactome_data['Reactome_ID'] = reactome_data.groupby(['UniprotAccession'])['Reactome_ID']\\\n",
    "                                            .transform(lambda x: '; '.join(x))\n",
    "reactome_data['Reactome_name'] = reactome_data.groupby(['UniprotAccession'])['Reactome_name']\\\n",
    "                                              .transform(lambda x: '; '.join(x))\n",
    "\n",
    "\n",
    "# Save the dataframe\n",
    "reactome_data.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\Reactome_data.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Protein Atlas Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_protein_atlas_data = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\proteinatlas.tsv', sep='\\t')\n",
    "\n",
    "# Retain only the necessary columns and change their names\n",
    "human_protein_atlas_data = human_protein_atlas_data[['Uniprot', \n",
    "                                                     'Gene', \n",
    "                                                     'Gene description', \n",
    "                                                     'Subcellular location']]\n",
    "human_protein_atlas_data.rename(columns = {'Uniprot' : 'UniprotAccession',\n",
    "                                           'Gene' : 'HPA_gene', \n",
    "                                           'Gene description' : 'HPA_gene_description', \n",
    "                                           'Subcellular location' : 'HPA_Subcellular_location'}, inplace = True)\n",
    "\n",
    "# Save the dataframe\n",
    "human_protein_atlas_data.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\Human_Protein_Atlas_data.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORUM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corum_data = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\CORUM_allComplexes.txt', delimiter='\\t', low_memory = False)\n",
    "\n",
    "# Select only human related pathways\n",
    "corum_data = corum_data[corum_data['Organism'] == 'Human']\n",
    "\n",
    "# Retain only the necessary columns and change their names\n",
    "corum_data = corum_data[['ComplexName', \n",
    "                         'subunits(UniProt IDs)']]\n",
    "\n",
    "corum_data.rename(columns = {'ComplexName' : 'CORUM_complexes',\n",
    "                             'subunits(UniProt IDs)' : 'CORUM_subunit_IDs'}, inplace = True)\n",
    "\n",
    "# Organize per UniProt ID\n",
    "corum_data = corum_data.assign(UniprotAccession = corum_data['CORUM_subunit_IDs'].str.split(';')).explode('UniprotAccession')\n",
    "corum_data['ComplexName'] = corum_data.groupby(['UniprotAccession'])['CORUM_complexes']\\\n",
    "                                      .transform(lambda x: '; '.join(x))\n",
    "corum_data['CORUM_subunit_IDs'] = corum_data.groupby(['UniprotAccession'])['CORUM_subunit_IDs']\\\n",
    "                                            .transform(lambda x: '; '.join(x))\n",
    "\n",
    "# reset the index and rearrange the columns\n",
    "corum_data.reset_index(inplace = True)\n",
    "corum_data = corum_data[['UniprotAccession',\n",
    "                         'CORUM_complexes',\n",
    "                         'CORUM_subunit_IDs']]\n",
    "\n",
    "# Save the dataframe\n",
    "corum_data.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\CORUM_data.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DisGeNet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of DisGeNet disease-associated proteins prior to filtration is : 1057185\n",
      "The amount of DisGeNet disease-associated proteins post-filtration is : 20594\n"
     ]
    }
   ],
   "source": [
    "disgenet_or_data = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\DisGeNet_all_gene_disease_associations.tsv.gz', compression = 'gzip', sep='\\t')\n",
    "disgenet_uniprot = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\DisGeNet_uniprot_mapping.tsv.gz', compression = 'gzip', sep='\\t')\n",
    "\n",
    "# Merge the UniProt IDs on the DisGeNet data\n",
    "disgenet_data = pd.merge(disgenet_or_data, disgenet_uniprot, left_on='geneId', right_on='GENEID')\n",
    "\n",
    "# Retain only the necessary columns and change their names\n",
    "disgenet_data = disgenet_data[['UniProtKB',  \n",
    "                               'diseaseName', \n",
    "                               'diseaseId',\n",
    "                               'diseaseSemanticType', \n",
    "                               'geneSymbol', \n",
    "                               'score']]\n",
    "\n",
    "disgenet_data.rename(columns = {'UniProtKB' : 'UniprotAccession',\n",
    "                                'diseaseName' : 'DisGeNet_disease_name', \n",
    "                                'diseaseId' : 'DisGeNet_disease_ID', \n",
    "                                'diseaseSemanticType' : 'DisGeNet_class', \n",
    "                                'geneSymbol' : 'DisGeNet_gene', \n",
    "                                'score' : 'DisGeNet_score'}, inplace = True)\n",
    "print(f'The amount of DisGeNet disease-associated proteins prior to filtration is : {disgenet_data.shape[0]}')\n",
    "\n",
    "# Filter the DisGeNet data\n",
    "disgenet_data = disgenet_data[disgenet_data['DisGeNet_score'] >= 0.35]\n",
    "print(f'The amount of DisGeNet disease-associated proteins post-filtration is : {disgenet_data.shape[0]}')\n",
    "\n",
    "# Organize per UniProt ID \n",
    "disgenet_data['DisGeNet_score'] = disgenet_data['DisGeNet_score'].astype(str)\n",
    "disgenet_data['DisGeNet_disease_name'] = disgenet_data.groupby(['UniprotAccession'])['DisGeNet_disease_name']\\\n",
    "                                         .transform(lambda x: '; '.join(x))\n",
    "\n",
    "disgenet_data['DisGeNet_disease_ID'] = disgenet_data.groupby(['UniprotAccession'])['DisGeNet_disease_ID']\\\n",
    "                                       .transform(lambda x: '; '.join(x))\n",
    "disgenet_data['DisGeNet_class'] = disgenet_data.groupby(['UniprotAccession'])['DisGeNet_class']\\\n",
    "                                                                  .transform(lambda x: '; '.join(x))\n",
    "disgenet_data['DisGeNet_gene'] = disgenet_data.groupby(['UniprotAccession'])['DisGeNet_gene']\\\n",
    "                                                                  .transform(lambda x: '; '.join(x))\n",
    "disgenet_data['DisGeNet_score'] = disgenet_data.groupby(['UniprotAccession'])['DisGeNet_score']\\\n",
    "                                                                   .transform(lambda x: '; '.join(x))\n",
    "\n",
    "disgenet_data.drop_duplicates(inplace = True)\n",
    "disgenet_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Save the dataframe\n",
    "disgenet_data.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\DisGeNet_data.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DisProt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "disprot_data = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\DisProt_data.tsv', sep='\\t')\n",
    "\n",
    "# Select only human related pathways\n",
    "disprot_data = disprot_data[disprot_data['organism'] == 'Homo sapiens']\n",
    "\n",
    "# Retain only the necessary columns and change their names\n",
    "disprot_data = disprot_data[['acc',  \n",
    "                             'name', \n",
    "                             'disprot_id']]\n",
    "\n",
    "disprot_data.rename(columns = {'acc' : 'UniprotAccession', \n",
    "                               'name' : 'DisProt_name', \n",
    "                               'disprot_id' : 'DisProt_ID'}, inplace = True)\n",
    "\n",
    "# Remove all duplicates and reset the index\n",
    "disprot_data.drop_duplicates(inplace = True)\n",
    "disprot_data.reset_index(inplace = True)\n",
    "disprot_data.drop(columns = {'index'}, inplace = True)\n",
    "\n",
    "# Save the dataframe\n",
    "disprot_data.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\DisProt_data.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all the metadata into 1 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_data = reactome_data.drop_duplicates('UniprotAccession')\n",
    "g_r = pd.merge(go_data, reactome_data, on = 'UniprotAccession', how='outer')\n",
    "\n",
    "human_protein_atlas_data = human_protein_atlas_data.drop_duplicates('UniprotAccession')\n",
    "g_r_h = pd.merge(g_r, human_protein_atlas_data, on = 'UniprotAccession', how='outer')\n",
    "\n",
    "corum_data = corum_data.drop_duplicates('UniprotAccession')\n",
    "g_r_h_c = pd.merge(g_r_h, corum_data, on = 'UniprotAccession', how='outer')\n",
    "\n",
    "disgenet_data = disgenet_data.drop_duplicates('UniprotAccession')\n",
    "g_r_h_c_d = pd.merge(g_r_h_c, disgenet_data, on = 'UniprotAccession', how='outer')\n",
    "\n",
    "disprot_data = disprot_data.drop_duplicates('UniprotAccession')\n",
    "metadata = pd.merge(g_r_h_c_d, disprot_data, on = 'UniprotAccession', how='outer')\n",
    "\n",
    "# Select only the UniProt IDs that are reviewed in UniProt and remove all duplicates\n",
    "uniprot1 = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\UniProt IDs 20_08_2020\\\\uniprot_homo_sapiens_reviewed.tab.gz', compression='gzip', sep = '\\t')\n",
    "uniprot = uniprot1['Entry'].tolist()\n",
    "metadata = metadata[metadata.UniprotAccession.isin(uniprot)]\n",
    "metadata.drop_duplicates(inplace = True)\n",
    "\n",
    "# Save the dataframe\n",
    "metadata.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\Metadata.csv', index = False, compression = 'gzip', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the metadata and the PPI data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI_data_filtered.csv', low_memory = False, sep='\\t')\n",
    "metadata = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\Metadata\\\\Filtered metadata\\\\Metadata.csv', low_memory = False, compression = 'gzip', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the metadata together with the PPI data\n",
    "ppi_A = pd.merge(ppi, metadata, how = 'left', left_on = ['UniprotAccessionA'], right_on = ['UniprotAccession'])\n",
    "ppi_meta = pd.merge(ppi_A, metadata, how = 'left', left_on = ['UniprotAccessionB'], right_on = ['UniprotAccession'])\n",
    "\n",
    "# Change the columns suffixes\n",
    "ppi_meta.columns = ppi_meta.columns.str.replace(r'_x', 'A')\n",
    "ppi_meta.columns = ppi_meta.columns.str.replace(r'_y', 'B')\n",
    "\n",
    "#Remove duplicate columns\n",
    "ppi_meta = ppi_meta.loc[:,~ppi_meta.columns.duplicated()]\n",
    "\n",
    "#Save the dataframe both in csv and txt format\n",
    "ppi_meta.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI_Metadata_IDs.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "ppi_meta.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI_Metadata_IDs.txt', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniprotAccessionA</th>\n",
       "      <th>UniprotAccessionB</th>\n",
       "      <th>BioGRID_IDA</th>\n",
       "      <th>BioGRID_IDB</th>\n",
       "      <th>STRING_IDA</th>\n",
       "      <th>STRING_IDB</th>\n",
       "      <th>Database</th>\n",
       "      <th>IntAct_score</th>\n",
       "      <th>BioGRID_score</th>\n",
       "      <th>STRING_score</th>\n",
       "      <th>...</th>\n",
       "      <th>HPA_Subcellular_locationB</th>\n",
       "      <th>CORUM_complexesB</th>\n",
       "      <th>CORUM_subunit_IDsB</th>\n",
       "      <th>DisGeNet_disease_nameB</th>\n",
       "      <th>DisGeNet_disease_IDB</th>\n",
       "      <th>DisGeNet_classB</th>\n",
       "      <th>DisGeNet_geneB</th>\n",
       "      <th>DisGeNet_scoreB</th>\n",
       "      <th>DisProt_nameB</th>\n",
       "      <th>DisProt_IDB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O15260</td>\n",
       "      <td>P84085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9606.ENSP00000361057</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O43731</td>\n",
       "      <td>P84085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9606.ENSP00000386918</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P42771</td>\n",
       "      <td>P84085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9606.ENSP00000418915</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A5PKW4</td>\n",
       "      <td>P84085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9606.ENSP00000020673</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O15155</td>\n",
       "      <td>P84085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9606.ENSP00000222547</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.921</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  UniprotAccessionA UniprotAccessionB BioGRID_IDA BioGRID_IDB  \\\n",
       "0            O15260            P84085         NaN         NaN   \n",
       "1            O43731            P84085         NaN         NaN   \n",
       "2            P42771            P84085         NaN         NaN   \n",
       "3            A5PKW4            P84085         NaN         NaN   \n",
       "4            O15155            P84085         NaN         NaN   \n",
       "\n",
       "             STRING_IDA            STRING_IDB Database  IntAct_score  \\\n",
       "0  9606.ENSP00000361057  9606.ENSP00000000233        S           NaN   \n",
       "1  9606.ENSP00000386918  9606.ENSP00000000233        S           NaN   \n",
       "2  9606.ENSP00000418915  9606.ENSP00000000233        S           NaN   \n",
       "3  9606.ENSP00000020673  9606.ENSP00000000233        S           NaN   \n",
       "4  9606.ENSP00000222547  9606.ENSP00000000233        S           NaN   \n",
       "\n",
       "   BioGRID_score  STRING_score  ... HPA_Subcellular_locationB  \\\n",
       "0            NaN         0.909  ...                       NaN   \n",
       "1            NaN         0.917  ...                       NaN   \n",
       "2            NaN         0.606  ...                       NaN   \n",
       "3            NaN         0.580  ...                       NaN   \n",
       "4            NaN         0.921  ...                       NaN   \n",
       "\n",
       "  CORUM_complexesB CORUM_subunit_IDsB DisGeNet_disease_nameB  \\\n",
       "0              NaN                NaN                    NaN   \n",
       "1              NaN                NaN                    NaN   \n",
       "2              NaN                NaN                    NaN   \n",
       "3              NaN                NaN                    NaN   \n",
       "4              NaN                NaN                    NaN   \n",
       "\n",
       "  DisGeNet_disease_IDB DisGeNet_classB DisGeNet_geneB DisGeNet_scoreB  \\\n",
       "0                  NaN             NaN            NaN             NaN   \n",
       "1                  NaN             NaN            NaN             NaN   \n",
       "2                  NaN             NaN            NaN             NaN   \n",
       "3                  NaN             NaN            NaN             NaN   \n",
       "4                  NaN             NaN            NaN             NaN   \n",
       "\n",
       "  DisProt_nameB DisProt_IDB  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           NaN         NaN  \n",
       "4           NaN         NaN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppi_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a NetworkX PPI graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppi = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI_Metadata_IDs.csv', encoding = 'utf-8', compression = 'gzip', low_memory = False, sep = '\\t')\n",
    "ppi2 = ppi.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the data from the dataframe into tuples and dictionaries so the nodes and edges have their corresponding attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4300: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "# create 2 dataframes with the A and B identifiers and rename the columns\n",
    "UA = ppi2[['UniprotAccessionA', \n",
    "           'BioGRID_IDA', \n",
    "           'STRING_IDA', \n",
    "           'Protein_nameA',  \n",
    "           'Gene_namesA', \n",
    "           'GO_biological_processA', \n",
    "           'GO_cellular_componentA', \n",
    "           'GO_molecular_functionA', \n",
    "           'Reactome_IDA', \n",
    "           'Reactome_nameA', \n",
    "           'HPA_geneA', \n",
    "           'HPA_gene_descriptionA',\n",
    "           'HPA_Subcellular_locationA', \n",
    "           'CORUM_complexesA', \n",
    "           'CORUM_subunit_IDsA', \n",
    "           'DisGeNet_disease_nameA', \n",
    "           'DisGeNet_disease_IDA', \n",
    "           'DisGeNet_classA',\n",
    "           'DisGeNet_geneA', \n",
    "           'DisGeNet_scoreA', \n",
    "           'DisProt_nameA', \n",
    "           'DisProt_IDA']]\n",
    "UA.rename(columns = {'UniprotAccessionA' : 'UniprotAccession',\n",
    "                     'BioGRID_IDA' : 'BioGRID_ID', \n",
    "                     'STRING_IDA' : 'STRING_ID', \n",
    "                     'Protein_nameA' : 'Protein_name', \n",
    "                     'Gene_namesA' : 'Gene_names',     \n",
    "                     'GO_biological_processA' : 'GO_biological_process', \n",
    "                     'GO_cellular_componentA' : 'GO_cellular_component', \n",
    "                     'GO_molecular_functionA' : 'GO_molecular_function', \n",
    "                     'Reactome_IDA' : 'Reactome_ID', \n",
    "                     'Reactome_nameA' : 'Reactome_name', \n",
    "                     'HPA_geneA' : 'HPA_gene', \n",
    "                     'HPA_gene_descriptionA' : 'HPA_gene_description', \n",
    "                     'HPA_Subcellular_locationA' : 'HPA_Subcellular_location',\n",
    "                     'CORUM_complexesA' : 'CORUM_complexes', \n",
    "                     'CORUM_subunit_IDsA' : 'CORUM_subunit_IDs', \n",
    "                     'DisGeNet_disease_nameA' : 'DisGeNet_disease_name', \n",
    "                     'DisGeNet_disease_IDA' : 'DisGeNet_disease_ID', \n",
    "                     'DisGeNet_classA' : 'DisGeNet_class', \n",
    "                     'DisGeNet_geneA' : 'DisGeNet_gene', \n",
    "                     'DisGeNet_scoreA' : 'DisGeNet_score', \n",
    "                     'DisProt_nameA' : 'DisProt_name', \n",
    "                     'DisProt_IDA' : 'DisProt_ID'}, inplace=True)\n",
    "\n",
    "UB = ppi2[['UniprotAccessionB', \n",
    "          'BioGRID_IDB', \n",
    "          'STRING_IDB', \n",
    "          'Protein_nameB', \n",
    "          'Gene_namesB', \n",
    "          'GO_biological_processB', \n",
    "          'GO_cellular_componentB', \n",
    "          'GO_molecular_functionB', \n",
    "          'Reactome_IDB', \n",
    "          'Reactome_nameB', \n",
    "          'HPA_geneB', \n",
    "          'HPA_gene_descriptionB', \n",
    "          'HPA_Subcellular_locationB', \n",
    "          'CORUM_complexesB', \n",
    "          'CORUM_subunit_IDsB', \n",
    "          'DisGeNet_disease_nameB', \n",
    "          'DisGeNet_disease_IDB', \n",
    "          'DisGeNet_classB',\n",
    "          'DisGeNet_geneB', \n",
    "          'DisGeNet_scoreB', \n",
    "          'DisProt_nameB', \n",
    "          'DisProt_IDB']]\n",
    "UB.rename(columns = {'UniprotAccessionB' : 'UniprotAccession',\n",
    "                     'BioGRID_IDB' : 'BioGRID_ID', \n",
    "                     'STRING_IDB' : 'STRING_ID', \n",
    "                     'Protein_nameB' : 'Protein_name',  \n",
    "                     'Gene_namesB' : 'Gene_names',     \n",
    "                     'GO_biological_processB' : 'GO_biological_process', \n",
    "                     'GO_cellular_componentB' : 'GO_cellular_component', \n",
    "                     'GO_molecular_functionB' : 'GO_molecular_function', \n",
    "                     'Reactome_IDB' : 'Reactome_ID', \n",
    "                     'Reactome_nameB' : 'Reactome_name', \n",
    "                     'HPA_geneB' : 'HPA_gene', \n",
    "                     'HPA_gene_descriptionB' : 'HPA_gene_description', \n",
    "                     'HPA_Subcellular_locationB' : 'HPA_Subcellular_location', \n",
    "                     'CORUM_complexesB' : 'CORUM_complexes', \n",
    "                     'CORUM_subunit_IDsB' : 'CORUM_subunit_IDs', \n",
    "                     'DisGeNet_disease_nameB' : 'DisGeNet_disease_name', \n",
    "                     'DisGeNet_disease_IDB' : 'DisGeNet_disease_ID', \n",
    "                     'DisGeNet_classB' : 'DisGeNet_class', \n",
    "                     'DisGeNet_geneB' : 'DisGeNet_gene', \n",
    "                     'DisGeNet_scoreB' : 'DisGeNet_score', \n",
    "                     'DisProt_nameB' : 'DisProt_name', \n",
    "                     'DisProt_IDB' : 'DisProt_ID'}, inplace=True)\n",
    "\n",
    "\n",
    "#add the two dataframes together and remove the duplicate rows\n",
    "U = UA.append(UB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the files that contain the Uniprot IDs and the STRING and BioGRID IDs\n",
    "ub = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\UB_IDs.csv', sep = '\\t')\n",
    "us = pd.read_csv(r'D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\US_IDs.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns to work with\n",
    "ub.rename(columns = {'UniProtKB_ID' : 'UniprotAccession', \n",
    "                     'BioGRID_ID' : 'BioGRID1'}, inplace=True)\n",
    "us.rename(columns = {'UniProtKB_ID' : 'UniprotAccession', \n",
    "                     'protein' : 'STRING'}, inplace=True)\n",
    "\n",
    "#adjust the ub dataframe to get all the BioGRID IDs per UniProt ID\n",
    "# Explode the cells to get each UniProt ID with a seperate BioGRID ID\n",
    "ub = ub.assign(BioGRID = ub['BioGRID1'].str.split(',')).explode('BioGRID')\n",
    "\n",
    "# Remove the other column and group the BioGRID IDs per UniProt ID and drop all the duplicates\n",
    "ub = ub[['UniprotAccession', 'BioGRID']]\n",
    "ub['BioGRID'] = ub.groupby(['UniprotAccession'])['BioGRID'].transform(lambda x: ', '.join(x))\n",
    "ub.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-98f884d93601>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U1.drop_duplicates(inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18683, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the dataframes together to get all possible information\n",
    "U = pd.merge(U, ub, left_on='UniprotAccession', right_on='UniprotAccession', how = 'left')\n",
    "U = pd.merge(U, us, left_on='UniprotAccession', right_on='UniprotAccession', how = 'left')\n",
    "\n",
    "# Retain only the necessary columns and rename the columns if need be\n",
    "U1 = U[['UniprotAccession', \n",
    "        'BioGRID', \n",
    "        'STRING',        \n",
    "        'Protein_name',  \n",
    "        'Gene_names', \n",
    "        'GO_biological_process', \n",
    "        'GO_cellular_component', \n",
    "        'GO_molecular_function',  \n",
    "        'Reactome_ID', \n",
    "        'Reactome_name', \n",
    "        'HPA_gene', \n",
    "        'HPA_gene_description', \n",
    "        'HPA_Subcellular_location', \n",
    "        'CORUM_complexes', \n",
    "        'CORUM_subunit_IDs', \n",
    "        'DisGeNet_disease_name', \n",
    "        'DisGeNet_disease_ID', \n",
    "        'DisGeNet_class', \n",
    "        'DisGeNet_gene', \n",
    "        'DisGeNet_score', \n",
    "        'DisProt_name', \n",
    "        'DisProt_ID']]\n",
    "U1.rename(columns = {'BioGRID' : 'BioGRID_ID', \n",
    "                     'STRING' : 'STRING_ID'}, inplace=True)\n",
    "\n",
    "# Remove all duplicates and print the amount of nodes the network will contain\n",
    "U1.drop_duplicates(inplace = True)\n",
    "uniprot_ids = U1.copy()\n",
    "uniprot_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the UniProt IDs as an index\n",
    "uniprot_ids.set_index('UniprotAccession', inplace = True)\n",
    "\n",
    "# Remove all duplicate terms in all the relevant columns\n",
    "uniprot_ids = uniprot_ids.astype(str)\n",
    "uniprot_ids['Reactome_ID'] = uniprot_ids['Reactome_ID'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['Reactome_name'] = uniprot_ids['Reactome_name'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['HPA_gene'] = uniprot_ids['HPA_gene'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['HPA_gene_description'] = uniprot_ids['HPA_gene_description'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['HPA_Subcellular_location'] = uniprot_ids['HPA_Subcellular_location'].str.split(',').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['CORUM_complexes'] = uniprot_ids['CORUM_complexes'].str.split(' / ').apply(lambda x: ' ; '.join(list(set(x))))\n",
    "uniprot_ids['CORUM_subunit_IDs'] = uniprot_ids['CORUM_subunit_IDs'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['DisGeNet_disease_name'] = uniprot_ids['DisGeNet_disease_name'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['DisGeNet_disease_ID'] = uniprot_ids['DisGeNet_disease_ID'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['DisGeNet_class'] = uniprot_ids['DisGeNet_class'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['DisGeNet_gene'] = uniprot_ids['DisGeNet_gene'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['DisGeNet_score'] = uniprot_ids['DisGeNet_score'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['DisProt_name'] = uniprot_ids['DisProt_name'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))\n",
    "uniprot_ids['DisProt_ID'] = uniprot_ids['DisProt_ID'].str.split(' / ').apply(lambda x: '; '.join(list(set(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18683"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all  the rows into dictionaries without the UniProt IDs\n",
    "x = uniprot_ids.to_dict('records')\n",
    "\n",
    "# Put the UniProt IDs in a list\n",
    "y = list(uniprot_ids.index.values)\n",
    "\n",
    "# Combine these two lists into a list of tuples for the network\n",
    "node_attr = []\n",
    "for i in range(len(y)):\n",
    "    node_attr.append(tuple([y[i], x[i]]))\n",
    "len(node_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611761"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe out of the columns with edge attributes and put the values per interaction in a dictionary\n",
    "ppi1 = ppi2[['IntAct_score', \n",
    "             'BioGRID_score', \n",
    "             'STRING_score', \n",
    "             'Database', \n",
    "             'BioGRID_ontology_ID']]\n",
    "\n",
    "x2 = ppi1.to_dict('records')\n",
    "\n",
    "# Create two lists that each contain the interaction pairs (one of the pair in one list and the other in the other list)\n",
    "u1 = list(ppi2.UniprotAccessionA.values)\n",
    "u2 = list(ppi2.UniprotAccessionB.values)\n",
    "\n",
    "# Combine these three lists into a list of tuples for the network\n",
    "edge_attr = []\n",
    "for i in range(len(x2)):\n",
    "    edge_attr.append(tuple([u1[i], u2[i], x2[i]]))\n",
    "len(edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network with the nodes and edges and their attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add the nodes\n",
    "G.add_nodes_from(node_attr)\n",
    "\n",
    "#Add the edges\n",
    "G.add_edges_from(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18683"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543266"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombine all the information in a dataframe (interaction and analysis data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543266, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the interactions from the network\n",
    "ppi = nx.to_pandas_edgelist(G)\n",
    "ppi.rename(columns = {'source' : 'UniprotAccession_A', \n",
    "                      'target' : 'UniprotAccession_B'}, inplace = True)\n",
    "\n",
    "# merge the uniprot IDs with the interactions\n",
    "ppi = pd.merge(ppi, uniprot_ids, left_on = 'UniprotAccession_A', right_on = 'UniprotAccession', how = 'left')\n",
    "ppi = pd.merge(ppi, uniprot_ids, left_on = 'UniprotAccession_B', right_on = 'UniprotAccession', how = 'left')\n",
    "\n",
    "# Alter the suffixes added\n",
    "ppi.columns = ppi.columns.str.replace(r'_x', '_A')\n",
    "ppi.columns = ppi.columns.str.replace(r'_y', '_B')\n",
    "ppi = ppi.loc[:,~ppi.columns.duplicated()]\n",
    "\n",
    "ppi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain the columns necessary\n",
    "ppi_final = ppi[['UniprotAccession_A', \n",
    "                 'BioGRID_ID_A', \n",
    "                 'STRING_ID_A', \n",
    "                 'Protein_name_A',  \n",
    "                 'Gene_names_A',\n",
    "                 'UniprotAccession_B', \n",
    "                 'BioGRID_ID_B', \n",
    "                 'STRING_ID_B', \n",
    "                 'Protein_name_B',  \n",
    "                 'Gene_names_B', \n",
    "                 'IntAct_score', \n",
    "                 'BioGRID_score', \n",
    "                 'STRING_score', \n",
    "                 'Database', \n",
    "                 'BioGRID_ontology_ID', \n",
    "                 'GO_biological_process_A', \n",
    "                 'GO_cellular_component_A', \n",
    "                 'GO_molecular_function_A', \n",
    "                 'Reactome_ID_A', \n",
    "                 'Reactome_name_A', \n",
    "                 'HPA_gene_A', \n",
    "                 'HPA_gene_description_A', \n",
    "                 'HPA_Subcellular_location_A', \n",
    "                 'CORUM_complexes_A', \n",
    "                 'CORUM_subunit_IDs_A', \n",
    "                 'DisGeNet_disease_name_A', \n",
    "                 'DisGeNet_disease_ID_A', \n",
    "                 'DisGeNet_class_A', \n",
    "                 'DisGeNet_gene_A', \n",
    "                 'DisGeNet_score_A', \n",
    "                 'DisProt_name_A', \n",
    "                 'DisProt_ID_A', \n",
    "                 'GO_biological_process_B', \n",
    "                 'GO_cellular_component_B', \n",
    "                 'GO_molecular_function_B', \n",
    "                 'Reactome_ID_B', \n",
    "                 'Reactome_name_B', \n",
    "                 'HPA_gene_B', \n",
    "                 'HPA_gene_description_B', \n",
    "                 'HPA_Subcellular_location_B', \n",
    "                 'CORUM_complexes_B', \n",
    "                 'CORUM_subunit_IDs_B', \n",
    "                 'DisGeNet_disease_name_B', \n",
    "                 'DisGeNet_disease_ID_B', \n",
    "                 'DisGeNet_class_B', \n",
    "                 'DisGeNet_gene_B', \n",
    "                 'DisGeNet_score_B', \n",
    "                 'DisProt_name_B', \n",
    "                 'DisProt_ID_B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S      494765\n",
       "BS      16455\n",
       "IBS     12819\n",
       "IS       9997\n",
       "I        8217\n",
       "IB       1013\n",
       "Name: Database, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppi_final['Database'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe both in csv and txt format and  save the uniprot_ids as well\n",
    "ppi_final.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI.csv', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')\n",
    "ppi_final.to_csv('D:\\\\Jana De Coster\\\\Documents\\\\Ugent\\\\2de master\\\\Master thesis\\\\Network\\\\Data interaction network\\\\PPI data 20_08_2020\\\\PPI with Uniprot IDs\\\\PPI.txt', encoding = 'utf-8', compression = 'gzip', index = False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
